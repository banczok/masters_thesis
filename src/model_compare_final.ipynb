{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61446,"databundleVersionId":6962461,"sourceType":"competition"},{"sourceId":8054097,"sourceType":"datasetVersion","datasetId":4322442},{"sourceId":150248402,"sourceType":"kernelVersion"},{"sourceId":122165,"sourceType":"modelInstanceVersion","modelInstanceId":102795,"modelId":127019},{"sourceId":165799,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":141071,"modelId":163679},{"sourceId":165890,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":141149,"modelId":163765}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\n!pip install einops","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-14T13:45:11.223144Z","iopub.execute_input":"2024-11-14T13:45:11.223579Z","iopub.status.idle":"2024-11-14T13:45:43.064783Z","shell.execute_reply.started":"2024-11-14T13:45:11.223537Z","shell.execute_reply":"2024-11-14T13:45:43.063708Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/pip-download-for-segmentation-models-pytorch\nProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/segmentation_models_pytorch-0.3.3-py3-none-any.whl\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.16.2)\nProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/pretrainedmodels-0.7.4.tar.gz (from segmentation-models-pytorch)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/efficientnet_pytorch-0.7.1.tar.gz (from segmentation-models-pytorch)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/timm-0.9.2-py3-none-any.whl (from segmentation-models-pytorch)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.2)\nProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/munch-4.0.0-py2.py3-none-any.whl (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.12.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.11.17)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=1d3d6bafb3570384def30981b7128fc0590a5750e177fa25d913656a46714a1a\n  Stored in directory: /root/.cache/pip/wheels/d2/e7/71/a031831a75a14914d29e2f255fcbc113d825ff4762d42f0315\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=79fbfdf6db86482c1cfa0a1d40908028d8f54d9955040db25ac9de3e8979c5e1\n  Stored in directory: /root/.cache/pip/wheels/10/53/cc/d9cbdaa15d821ad4845e69994708dcad78fcddf4c92a753bdf\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.9.12\n    Uninstalling timm-0.9.12:\n      Successfully uninstalled timm-0.9.12\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install monai","metadata":{"execution":{"iopub.status.busy":"2024-11-14T13:45:43.067044Z","iopub.execute_input":"2024-11-14T13:45:43.067813Z","iopub.status.idle":"2024-11-14T13:45:57.017097Z","shell.execute_reply.started":"2024-11-14T13:45:43.067776Z","shell.execute_reply":"2024-11-14T13:45:57.016037Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.24 in /opt/conda/lib/python3.10/site-packages (from monai) (1.24.4)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.4.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch\nimport segmentation_models_pytorch as smp\nimport matplotlib.pyplot as plt\nimport cv2\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import clear_output\nimport plotly.graph_objects as go\nfrom IPython.display import display, clear_output\nimport plotly.express as px\nimport pandas as pd\nimport random\nfrom torch import nn\n\nfrom torch.cuda.amp import GradScaler, autocast\nimport math\nimport tqdm\nimport monai","metadata":{"execution":{"iopub.status.busy":"2024-11-14T13:45:57.018614Z","iopub.execute_input":"2024-11-14T13:45:57.018986Z","iopub.status.idle":"2024-11-14T13:46:47.472125Z","shell.execute_reply.started":"2024-11-14T13:45:57.018947Z","shell.execute_reply":"2024-11-14T13:46:47.471301Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-11-14 13:46:38.824589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-11-14 13:46:38.824731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-11-14 13:46:38.970497: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class newDataset(Dataset):\n    def __init__(self, image_files, mask_files, input_size=(512,512), transform=None):\n        self.image_files=image_files\n        self.mask_files=mask_files\n        self.input_size=input_size\n        self.transform=transform\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        image_path=self.image_files[idx]\n        image = cv2.imread(image_path, 0)\n        orig_size = image.shape\n        \n        image = self.image_histogram_equalization(image.astype('float32'))\n        image = image/image.max()\n        image=torch.tensor(image)\n        if self.transform:\n            image=self.augment_image(image)\n        \n        mask = cv2.imread(self.mask_files[idx], 0)\n        mask = mask / 255.\n        mask=torch.tensor(mask)\n        \n        return image, mask\n    \n    def image_histogram_equalization(self, image, number_bins=256):\n        image_histogram, bins = np.histogram(image.flatten(), number_bins, density=True)\n        cdf = image_histogram.cumsum() \n        cdf = (number_bins-1) * cdf / cdf[-1] \n        \n        image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n    \n        return image_equalized.reshape(image.shape)\n    \n    def augment_image(self, image):\n        shape = (*image.shape, 1 )\n        image_np = image.reshape(shape).numpy()\n        augmented = self.transform(image = image_np)\n        augmented_image = augmented['image']\n        augmented_image = augmented_image.reshape(augmented_image.shape[:-1])\n        augmented_image = torch.tensor(augmented_image, dtype=torch.float32)\n\n        \n        return augmented_image\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    if rle == '':\n        rle = '1 0'\n    return rle\n\n\ndef remove_small_objects(img, min_size):\n    # Find all connected components (labels)\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=8)\n\n    # Create a mask where small objects are removed\n    new_img = np.zeros_like(img)\n    for label in range(1, num_labels):\n        if stats[label, cv2.CC_STAT_AREA] >= min_size:\n            new_img[labels == label] = 255\n\n    return new_img\n\n\nclass patchImage():\n    def __init__(self, patch_size=768, patch_overlap=0.15):\n        self.patch_size = patch_size\n        self.patch_overlap = patch_overlap\n        \n    def extract_patches(self, image):\n        patches = []\n        def calculate_dynamic_step(img_dim, patch_dim, overlap_fraction):\n            overlap = int(patch_dim * overlap_fraction)\n            step = patch_dim - overlap\n            num_patches = math.ceil((img_dim - overlap) / step)\n            step = (img_dim - patch_dim) / (num_patches - 1) if num_patches > 1 else 0\n            return step, num_patches\n\n        step_h, num_patches_h = calculate_dynamic_step(image.shape[0], self.patch_size, self.patch_overlap)\n        step_w, num_patches_w = calculate_dynamic_step(image.shape[1], self.patch_size, self.patch_overlap)\n        patches = []\n        \n        for i in range(num_patches_h):\n            for j in range(num_patches_w):\n                y = int(i * step_h)\n                x = int(j * step_w)\n                patch_img = image[y:y + self.patch_size, x:x + self.patch_size]\n                patches.append(patch_img.numpy())\n\n        return patches\n\n    \n    def reconstruct_from_patches(self, patches, original_shape, patch_size=768, patch_overlap=0.2):\n        # Calculate the step size and number of patches along each dimension\n        overlap = int(patch_size * patch_overlap)\n        step = patch_size - overlap\n\n        # Calculate the dynamic step if needed, as in the extract_patches function\n        def calculate_dynamic_step(img_dim, patch_dim, num_patches):\n            if num_patches > 1:\n                return (img_dim - patch_dim) / (num_patches - 1)\n            else:\n                return 0\n\n        # Determine the number of patches along each dimension\n        num_patches_h = int(np.ceil((original_shape[0] - overlap) / step))\n        num_patches_w = int(np.ceil((original_shape[1] - overlap) / step))\n\n        # Recalculate step size based on the actual number of patches (for edge cases)\n        step_h = calculate_dynamic_step(original_shape[0], patch_size, num_patches_h)\n        step_w = calculate_dynamic_step(original_shape[1], patch_size, num_patches_w)\n\n        # Initialize an empty array to hold the reconstructed image\n        reconstructed_image = np.zeros(original_shape, dtype=patches[0].dtype)\n\n        # Loop through each patch and place it in the reconstructed image\n        patch_idx = 0\n        for i in range(num_patches_h):\n            for j in range(num_patches_w):\n                y = int(i * step_h)\n                x = int(j * step_w)\n\n                # If a patch goes beyond the image boundaries, trim the patch to fit\n                patch = patches[patch_idx]\n                patch_h, patch_w = patch.shape[:2]\n                end_y = min(y + patch_h, original_shape[0])\n                end_x = min(x + patch_w, original_shape[1])\n\n                # Place the patch in the reconstructed image\n                reconstructed_image[y:end_y, x:end_x] = patch[:(end_y-y), :(end_x-x)]\n                patch_idx += 1\n\n        return reconstructed_image\n\nclass SegmentationPerformance:\n    def __init__(self, num_samples=5, device='cuda'):\n        self.metrics_sum = {'Precision': 0, 'Recall': 0, 'Accuracy': 0, 'Dice Coefficient': 0, 'IoU': 0}\n        self.count = 0\n        self.total_loss = 0.0\n        self.total_loss1 = 0.0\n        self.saved_samples = []\n        self.num_samples = num_samples\n        self.device = device\n        self.surface_dice = 0.0\n\n    def precision_score_(self, groundtruth_mask, pred_mask):\n        intersect = torch.sum(pred_mask * groundtruth_mask)\n        total_pixel_pred = torch.sum(pred_mask)\n        precision = intersect.float() / total_pixel_pred.float() if total_pixel_pred != 0 else torch.tensor(0.0, device=groundtruth_mask.device)\n        return precision.item()\n\n    def recall_score_(self, groundtruth_mask, pred_mask):\n        intersect = torch.sum(pred_mask * groundtruth_mask)\n        total_pixel_truth = torch.sum(groundtruth_mask)\n        recall = intersect.float() / total_pixel_truth.float() if total_pixel_truth != 0 else torch.tensor(0.0, device=groundtruth_mask.device)\n        return recall.item()\n\n    def accuracy(self, groundtruth_mask, pred_mask):\n        intersect = torch.sum(pred_mask * groundtruth_mask)\n        union = torch.sum(pred_mask) + torch.sum(groundtruth_mask) - intersect\n        xor = torch.sum(groundtruth_mask == pred_mask)\n        acc = xor.float() / (union + xor - intersect).float() if (union + xor - intersect) != 0 else torch.tensor(0.0, device=self.device)\n        return acc.item()\n\n    def dice_coef(self, groundtruth_mask, pred_mask):\n        intersect = torch.sum(pred_mask * groundtruth_mask)\n        total_sum = torch.sum(pred_mask) + torch.sum(groundtruth_mask)\n        dice = (2 * intersect).float() / total_sum.float() if total_sum != 0 else torch.tensor(0.0, device=self.device)\n        return dice.item()\n\n    def iou(self, groundtruth_mask, pred_mask):\n        intersect = torch.sum(pred_mask * groundtruth_mask)\n        union = torch.sum(pred_mask) + torch.sum(groundtruth_mask) - intersect\n        iou = intersect.float() / union.float() if union != 0 else torch.tensor(0.0, device=self.device)\n        return iou.item()\n\n    def update_metrics_and_save_sample(self, groundtruth_mask, pred_mask, loss=None,loss1=None, image=None, gt_mask=None, pred_mask_sample=None):\n        self.metrics_sum['Precision'] += self.precision_score_(groundtruth_mask, pred_mask)\n        self.metrics_sum['Recall'] += self.recall_score_(groundtruth_mask, pred_mask)\n        self.metrics_sum['Accuracy'] += self.accuracy(groundtruth_mask, pred_mask)\n        self.metrics_sum['Dice Coefficient'] += self.dice_coef(groundtruth_mask, pred_mask)\n        self.metrics_sum['IoU'] += self.iou(groundtruth_mask, pred_mask)\n        if loss is not None:\n            self.total_loss += loss.item()\n\n        if loss1 is not None:\n            self.total_loss1 += loss1.item()\n    \n        if image is not None:\n            # Convert to CPU for plotting\n            self.saved_samples.append((image.cpu().numpy(), gt_mask.cpu().numpy(), pred_mask_sample.cpu().numpy()))\n\n        self.count += 1\n\n    def get_average_metrics(self):\n        average_metrics = {metric: value / self.count for metric, value in self.metrics_sum.items()}\n        average_metrics['Average Loss'] = self.total_loss / self.count if self.count != 0 else 0\n        average_metrics['Average Loss1'] = self.total_loss1 / self.count if self.count != 0 else 0\n        average_metrics['Avg Surface Dice'] = self.surface_dice \n        return average_metrics\n\n    def report(self):\n        metrics = self.get_average_metrics()\n        return pd.DataFrame([metrics])\n    \n    def plot_saved_samples(self, figsize=(15, 15)):\n        if not self.saved_samples:\n            print(\"No samples saved for plotting.\")\n            return\n\n        plt.figure(figsize=figsize)\n\n        for i, (image, groundtruth_mask, predicted_mask) in enumerate(self.saved_samples):\n            if image.ndim == 3:\n                if image.shape[0] == 3:  \n                    image = image.transpose(1, 2, 0)\n                elif image.shape[0] == 1:  \n                    image = image.squeeze(0)  #\n\n            image = (image - image.min()) / (image.max() - image.min()) if image.max() != image.min() else image\n\n            plt.subplot(self.num_samples, 3, i * 3 + 1)\n            plt.imshow(image, cmap='gray' if image.ndim == 2 else None)\n            plt.title('Image')\n            plt.axis('off')\n\n            plt.subplot(self.num_samples, 3, i * 3 + 2)\n            plt.imshow(groundtruth_mask.squeeze(), cmap='gray')\n            plt.title('Ground Truth Mask')\n            plt.axis('off')\n\n            plt.subplot(self.num_samples, 3, i * 3 + 3)\n            plt.imshow(predicted_mask.squeeze(), cmap='gray')\n            plt.title('Predicted Mask')\n            plt.axis('off')\n\n        plt.tight_layout()\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T13:46:47.474019Z","iopub.execute_input":"2024-11-14T13:46:47.474909Z","iopub.status.idle":"2024-11-14T13:46:47.522340Z","shell.execute_reply.started":"2024-11-14T13:46:47.474881Z","shell.execute_reply":"2024-11-14T13:46:47.521438Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"_NEIGHBOUR_CODE_TO_NORMALS = [[[0, 0, 0]], [[0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125]],\n                              [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n                              [[0.125, -0.125, 0.125]],\n                              [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25]],\n                              [[0.125, -0.125, 0.125], [-0.125, -0.125,\n                                                        0.125]],\n                              [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25],\n                               [0.125, 0.125, 0.125]], [[-0.125, 0.125,\n                                                         0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, 0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25]],\n                              [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n                              [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25],\n                               [-0.125, 0.125, -0.125]],\n                              [[-0.5, 0.0, 0.0], [-0.25, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[0.5, 0.0, 0.0], [0.5, 0.0, 0.0]],\n                              [[0.125, -0.125, -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25]],\n                              [[-0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, -0.5, 0.0], [0.25, 0.25, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [0.125, -0.125,\n                                                        -0.125]],\n                              [[0.0, 0.0, -0.5], [0.25, 0.25, 0.25],\n                               [-0.125, -0.125, -0.125]],\n                              [[-0.125, -0.125, 0.125], [0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25],\n                               [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125,\n                                                        -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[0.125, 0.125, 0.125], [0.375, 0.375, 0.375],\n                               [0.0, -0.25, 0.25], [-0.25, 0.0, 0.25]],\n                              [[0.125, -0.125, -0.125], [0.25, -0.25, 0.0],\n                               [0.25, -0.25, 0.0]],\n                              [[0.375, 0.375, 0.375], [0.0, 0.25, -0.25],\n                               [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n                              [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125],\n                               [-0.25, -0.25, -0.25], [0.125, 0.125, 0.125]],\n                              [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125],\n                               [-0.25, -0.25, -0.25]], [[0.125, -0.125,\n                                                         0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n                              [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125],\n                               [0.25, 0.25, -0.25]],\n                              [[0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [-0.25, -0.0, -0.25],\n                               [0.25, 0.0, 0.25]],\n                              [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.375, -0.375, 0.375], [-0.0, 0.25, 0.25],\n                               [0.125, 0.125, -0.125], [-0.25, -0.0, -0.25]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.25, 0.25, -0.25], [0.25, 0.25, -0.25],\n                               [0.125, 0.125, -0.125], [-0.125, -0.125,\n                                                        0.125]],\n                              [[0.125, -0.125, 0.125], [0.25, -0.25, 0.0],\n                               [0.25, -0.25, 0.0]],\n                              [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25],\n                               [-0.125, 0.125, -0.125], [0.125, -0.125,\n                                                         0.125]],\n                              [[0.0, 0.25, -0.25], [0.375, -0.375, -0.375],\n                               [-0.125, 0.125, 0.125], [0.25, 0.25, 0.0]],\n                              [[-0.5, 0.0, 0.0], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0]],\n                              [[0.0, 0.5, 0.0], [-0.25, 0.25, 0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, 0.5, 0.0], [0.125, -0.125, 0.125],\n                               [-0.25, 0.25, -0.25]],\n                              [[0.0, 0.5, 0.0], [0.0, -0.5, 0.0]],\n                              [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.375, -0.375, -0.375], [-0.25, 0.0, 0.25],\n                               [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n                              [[0.125, 0.125, 0.125], [0.0, -0.5, 0.0],\n                               [-0.25, -0.25, -0.25], [-0.125, -0.125,\n                                                       -0.125]],\n                              [[0.0, -0.5, 0.0], [-0.25, -0.25, -0.25],\n                               [-0.125, -0.125, -0.125]],\n                              [[-0.125, 0.125, 0.125], [0.25, -0.25, 0.0],\n                               [-0.25, 0.25, 0.0]],\n                              [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25],\n                               [-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.375, 0.375, -0.375], [-0.25, -0.25, 0.0],\n                               [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n                              [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0],\n                               [0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n                              [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.25, -0.25, 0.0],\n                               [-0.25, -0.25, 0.0]],\n                              [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0]],\n                              [[-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [-0.25, -0.25, 0.0],\n                               [0.25, 0.25, -0.0]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25]],\n                              [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.375, -0.375, 0.375], [0.0, -0.25, -0.25],\n                               [-0.125, 0.125, -0.125], [0.25, 0.25, 0.0]],\n                              [[-0.125, -0.125, 0.125], [-0.125, 0.125,\n                                                         0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25],\n                               [-0.25, 0.0, 0.25]],\n                              [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.25, 0.25, -0.25], [-0.25, 0.25, -0.25],\n                               [-0.125, 0.125, -0.125],\n                               [-0.125, 0.125, -0.125]],\n                              [[-0.25, 0.0, -0.25], [0.375, -0.375, -0.375],\n                               [0.0, 0.25, -0.25], [-0.125, 0.125, 0.125]],\n                              [[0.5, 0.0, 0.0], [-0.25, 0.25, -0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n                              [[-0.0, 0.0, 0.5], [-0.25, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25],\n                               [0.25, 0.0, -0.25]],\n                              [[-0.25, -0.0, -0.25], [-0.375, 0.375, 0.375],\n                               [-0.25, -0.25, 0.0], [-0.125, 0.125, 0.125]],\n                              [[0.0, 0.0, -0.5], [0.25, 0.25, -0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.0, 0.0, 0.5], [0.0, 0.0, 0.5]],\n                              [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125],\n                               [0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n                              [[0.125, 0.125, 0.125], [0.25, 0.25, 0.25],\n                               [0.0, 0.0, 0.5]],\n                              [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25],\n                               [-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n                              [[0.125, -0.125, 0.125], [0.25, 0.0, 0.25],\n                               [0.25, 0.0, 0.25]],\n                              [[0.25, 0.0, 0.25], [-0.375, -0.375, 0.375],\n                               [-0.25, 0.25, 0.0], [-0.125, -0.125, 0.125]],\n                              [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.25, 0.0, 0.25],\n                               [0.25, 0.0, 0.25]],\n                              [[0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n                              [[-0.125, -0.125, 0.125], [0.125, -0.125,\n                                                         0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [0.0, -0.25, 0.25],\n                               [0.0, 0.25, -0.25]],\n                              [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125],\n                               [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25],\n                               [0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n                              [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125], [0.125, 0.125, 0.125]],\n                              [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25],\n                               [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, -0.125]],\n                              [[0.5, 0.0, -0.0], [0.25, -0.25, -0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125],\n                               [-0.25, 0.25, 0.25], [0.125, -0.125, -0.125]],\n                              [[0.375, -0.375, 0.375], [0.0, 0.25, 0.25],\n                               [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n                              [[0.0, -0.5, 0.0], [-0.25, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.375, -0.375, 0.375], [0.25, -0.25, 0.0],\n                               [0.0, 0.25, 0.25], [-0.125, -0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [-0.25, 0.25, 0.25],\n                               [0.0, 0.0, 0.5]],\n                              [[0.125, 0.125, 0.125], [0.0, 0.25, 0.25],\n                               [0.0, 0.25, 0.25]],\n                              [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n                              [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25],\n                               [0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [0.125, 0.125, 0.125]],\n                              [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125]], [[0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n                              [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [0.125, 0.125, 0.125]],\n                              [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25],\n                               [0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n                              [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n                              [[0.125, 0.125, 0.125], [0.0, 0.25, 0.25],\n                               [0.0, 0.25, 0.25]],\n                              [[-0.125, 0.125, 0.125], [-0.25, 0.25, 0.25],\n                               [0.0, 0.0, 0.5]],\n                              [[-0.375, -0.375, 0.375], [0.25, -0.25, 0.0],\n                               [0.0, 0.25, 0.25], [-0.125, -0.125, 0.125]],\n                              [[0.0, -0.5, 0.0], [-0.25, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[0.375, -0.375, 0.375], [0.0, 0.25, 0.25],\n                               [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n                              [[-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125],\n                               [-0.25, 0.25, 0.25], [0.125, -0.125, -0.125]],\n                              [[0.5, 0.0, -0.0], [0.25, -0.25, -0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25],\n                               [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125], [0.125, 0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25],\n                               [0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n                              [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125],\n                               [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [0.0, -0.25, 0.25],\n                               [0.0, 0.25, -0.25]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [0.125, -0.125,\n                                                         0.125]],\n                              [[0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n                              [[0.125, 0.125, 0.125], [0.25, 0.0, 0.25],\n                               [0.25, 0.0, 0.25]],\n                              [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.25, 0.0, 0.25], [-0.375, -0.375, 0.375],\n                               [-0.25, 0.25, 0.0], [-0.125, -0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [0.25, 0.0, 0.25],\n                               [0.25, 0.0, 0.25]],\n                              [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25],\n                               [0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n                              [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.25, 0.25, 0.25],\n                               [0.0, 0.0, 0.5]],\n                              [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125],\n                               [0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n                              [[-0.0, 0.0, 0.5], [0.0, 0.0, 0.5]],\n                              [[0.0, 0.0, -0.5], [0.25, 0.25, -0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.25, -0.0, -0.25], [-0.375, 0.375, 0.375],\n                               [-0.25, -0.25, 0.0], [-0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25],\n                               [0.25, 0.0, -0.25]],\n                              [[-0.0, 0.0, 0.5], [-0.25, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n                              [[0.5, 0.0, 0.0], [-0.25, 0.25, -0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[-0.25, 0.0, -0.25], [0.375, -0.375, -0.375],\n                               [0.0, 0.25, -0.25], [-0.125, 0.125, 0.125]],\n                              [[-0.25, 0.25, -0.25], [-0.25, 0.25, -0.25],\n                               [-0.125, 0.125, -0.125],\n                               [-0.125, 0.125, -0.125]],\n                              [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25],\n                               [-0.25, 0.0, 0.25]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [-0.125, 0.125,\n                                                         0.125]],\n                              [[0.375, -0.375, 0.375], [0.0, -0.25, -0.25],\n                               [-0.125, 0.125, -0.125], [0.25, 0.25, 0.0]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25]],\n                              [[-0.125, -0.125, 0.125], [-0.25, -0.25, 0.0],\n                               [0.25, 0.25, -0.0]],\n                              [[-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125]],\n                              [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0]],\n                              [[0.125, 0.125, 0.125], [-0.25, -0.25, 0.0],\n                               [-0.25, -0.25, 0.0]],\n                              [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0],\n                               [-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n                              [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.375, 0.375, -0.375], [-0.25, -0.25, 0.0],\n                               [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n                              [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25],\n                               [-0.125, -0.125, 0.125],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.25, -0.25, 0.0],\n                               [-0.25, 0.25, 0.0]],\n                              [[0.0, -0.5, 0.0], [-0.25, -0.25, -0.25],\n                               [-0.125, -0.125, -0.125]],\n                              [[0.125, 0.125, 0.125], [0.0, -0.5, 0.0],\n                               [-0.25, -0.25, -0.25], [-0.125, -0.125,\n                                                       -0.125]],\n                              [[-0.375, -0.375, -0.375], [-0.25, 0.0, 0.25],\n                               [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n                              [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0],\n                               [0.125, -0.125, 0.125]],\n                              [[0.0, 0.5, 0.0], [0.0, -0.5, 0.0]],\n                              [[0.0, 0.5, 0.0], [0.125, -0.125, 0.125],\n                               [-0.25, 0.25, -0.25]],\n                              [[0.0, 0.5, 0.0], [-0.25, 0.25, 0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0]],\n                              [[-0.5, 0.0, 0.0], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.0, 0.25, -0.25], [0.375, -0.375, -0.375],\n                               [-0.125, 0.125, 0.125], [0.25, 0.25, 0.0]],\n                              [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25],\n                               [-0.125, 0.125, -0.125], [0.125, -0.125,\n                                                         0.125]],\n                              [[0.125, -0.125, 0.125], [0.25, -0.25, 0.0],\n                               [0.25, -0.25, 0.0]],\n                              [[0.25, 0.25, -0.25], [0.25, 0.25, -0.25],\n                               [0.125, 0.125, -0.125], [-0.125, -0.125,\n                                                        0.125]],\n                              [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[-0.375, -0.375, 0.375], [-0.0, 0.25, 0.25],\n                               [0.125, 0.125, -0.125], [-0.25, -0.0, -0.25]],\n                              [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25],\n                               [0.125, -0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [-0.25, -0.0, -0.25],\n                               [0.25, 0.0, 0.25]],\n                              [[0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125],\n                               [0.25, 0.25, -0.25]],\n                              [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n                              [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n                              [[0.125, -0.125, 0.125]],\n                              [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125],\n                               [-0.25, -0.25, -0.25]],\n                              [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125],\n                               [-0.25, -0.25, -0.25], [0.125, 0.125, 0.125]],\n                              [[0.375, 0.375, 0.375], [0.0, 0.25, -0.25],\n                               [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n                              [[0.125, -0.125, -0.125], [0.25, -0.25, 0.0],\n                               [0.25, -0.25, 0.0]],\n                              [[0.125, 0.125, 0.125], [0.375, 0.375, 0.375],\n                               [0.0, -0.25, 0.25], [-0.25, 0.0, 0.25]],\n                              [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125], [0.125, -0.125,\n                                                        -0.125]],\n                              [[-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25],\n                               [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125], [0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, 0.0, -0.5], [0.25, 0.25, 0.25],\n                               [-0.125, -0.125, -0.125]],\n                              [[0.125, -0.125, 0.125], [0.125, -0.125,\n                                                        -0.125]],\n                              [[0.0, -0.5, 0.0], [0.25, 0.25, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[-0.125, -0.125, 0.125],\n                               [0.125, -0.125, -0.125]],\n                              [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25]],\n                              [[0.125, -0.125, -0.125]],\n                              [[0.5, 0.0, 0.0], [0.5, 0.0, 0.0]],\n                              [[-0.5, 0.0, 0.0], [-0.25, 0.25, 0.25],\n                               [-0.125, 0.125, 0.125]],\n                              [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25],\n                               [-0.125, 0.125, -0.125]],\n                              [[0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n                              [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25],\n                               [-0.125, -0.125, 0.125]],\n                              [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25]],\n                              [[0.125, 0.125, 0.125], [-0.125, 0.125, 0.125]],\n                              [[-0.125, 0.125, 0.125]],\n                              [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25],\n                               [0.125, 0.125, 0.125]],\n                              [[0.125, -0.125, 0.125], [-0.125, -0.125,\n                                                        0.125]],\n                              [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25]],\n                              [[0.125, -0.125, 0.125]],\n                              [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n                              [[-0.125, -0.125, 0.125]],\n                              [[0.125, 0.125, 0.125]], [[0, 0, 0]]]\n\n\nimport torch.nn as nn\n\ndevice = torch.device('cuda')  # can be 'cpu'\n\n# PyTorch version dependence on index data type\ntorch_ver_major = int(torch.__version__.split('.')[0])\ndtype_index = torch.int32 if torch_ver_major >= 2 else torch.long\n\ndef create_table_neighbour_code_to_surface_area(spacing_mm):\n    \"\"\"Returns an array mapping neighbourhood code to the surface elements area.\n\n  Note that the normals encode the initial surface area. This function computes\n  the area corresponding to the given `spacing_mm`.\n\n  Args:\n    spacing_mm: 3-element list-like structure. Voxel spacing in x0, x1 and x2\n      direction.\n  \"\"\"\n    # compute the area for all 256 possible surface elements\n    # (given a 2x2x2 neighbourhood) according to the spacing_mm\n    neighbour_code_to_surface_area = np.zeros([256])\n    for code in range(256):\n        normals = np.array(_NEIGHBOUR_CODE_TO_NORMALS[code])\n        sum_area = 0\n        for normal_idx in range(normals.shape[0]):\n            # normal vector\n            n = np.zeros([3])\n            n[0] = normals[normal_idx, 0] * spacing_mm[1] * spacing_mm[2]\n            n[1] = normals[normal_idx, 1] * spacing_mm[0] * spacing_mm[2]\n            n[2] = normals[normal_idx, 2] * spacing_mm[0] * spacing_mm[1]\n            area = np.linalg.norm(n)\n            sum_area += area\n        neighbour_code_to_surface_area[code] = sum_area\n\n    return neighbour_code_to_surface_area.astype(np.float32)\n\ndef rle_decode(mask_rle: str, shape: tuple) -> np.array:\n    \"\"\"\n    Decode rle string\n    https://www.kaggle.com/code/paulorzp/run-length-encode-and-decode/script\n    https://www.kaggle.com/stainsby/fast-tested-rle\n\n    Args:\n      mask_rle: run length (rle) as string\n      shape: (height, width) of the mask\n\n    Returns:\n      array[uint8], 1 - mask, 0 - background\n    \"\"\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\n\ndef compute_area(y: list, unfold: nn.Unfold, area: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Args:\n      y (list[Tensor]): A pair of consecutive slices of mask\n      unfold: nn.Unfold(kernel_size=(2, 2), padding=1)\n      area (Tensor): surface area for 256 patterns (256, )\n\n    Returns:\n      Surface area of surface in 2x2x2 cube\n    \"\"\"\n    # Two layers of segmentation masks\n    yy = torch.stack(y, dim=0).to(torch.float16).unsqueeze(0)\n    # (batch_size=1, nch=2, H, W) \n    # bit (0/1) but unfold requires float\n\n    # unfold slides through the volume like a convolution\n    # 2x2 kernel returns 8 values (2 channels * 2x2)\n    cubes_float = unfold(yy).squeeze(0)  # (8, n_cubes)\n\n    # Each of the 8 values are either 0 or 1\n    # Convert those 8 bits to one uint8\n    cubes_byte = torch.zeros(cubes_float.size(1), dtype=dtype_index, device=device)\n    # indices are required to be int32 or long for area[cube_byte] below, not uint8\n    # Can be int32 for torch 2.0.0, int32 raise IndexError in torch 1.13.1.\n    \n    for k in range(8):\n        cubes_byte += cubes_float[k, :].to(dtype_index) << k\n\n    # Use area lookup table: pattern index -> area [float]\n    cubes_area = area[cubes_byte]\n\n    return cubes_area\n\n\ndef compute_surface_dice_score(submit: pd.DataFrame, label: pd.DataFrame) -> float:\n    \"\"\"\n    Compute surface Dice score for one 3D volume\n\n    submit (pd.DataFrame): submission file with id and rle\n    label (pd.DataFrame): ground truth id, rle, and also image height, width\n    \"\"\"\n    # submit and label must contain exact same id in same order\n    assert (submit['id'] == label['id']).all()\n    assert len(label) > 0\n\n    # All height, width must be the same\n    len(label['height'].unique()) == 1\n    len(label['width'].unique()) == 1\n\n    # Surface area lookup table: Tensor[float32] (256, )\n    area = create_table_neighbour_code_to_surface_area((1, 1, 1))\n    area = torch.from_numpy(area).to(device)  # torch.float32\n\n    # Slide through the volume like a convolution\n    unfold = torch.nn.Unfold(kernel_size=(2, 2), padding=1)\n\n    r = label.iloc[0]\n    h, w = r['height'], r['width']\n    n_slices = len(label)\n\n    # Padding before first slice\n    y0 = y0_pred = torch.zeros((h, w), dtype=torch.uint8, device=device)\n\n    num = 0     # numerator of surface Dice\n    denom = 0   # denominator\n    for i in range(n_slices + 1):\n        # Load one slice\n        if i < n_slices:\n            r = label.iloc[i]\n            y1 = rle_decode(r['rle'], (h, w))\n            y1 = torch.from_numpy(y1).to(device)\n\n            r = submit.iloc[i]\n            y1_pred = rle_decode(r['rle'], (h, w))\n            y1_pred = torch.from_numpy(y1_pred).to(device)\n        else:\n            # Padding after the last slice\n            y1 = y1_pred = torch.zeros((h, w), dtype=torch.uint8, device=device)\n\n        # Compute the surface area between two slices (n_cubes,)\n        area_pred = compute_area([y0_pred, y1_pred], unfold, area)\n        area_true = compute_area([y0, y1], unfold, area)\n\n        # True positive cube indices\n        idx = torch.logical_and(area_pred > 0, area_true > 0)\n\n        # Surface dice numerator and denominator\n        num += area_pred[idx].sum() + area_true[idx].sum()\n        denom += area_pred.sum() + area_true.sum()\n\n        # Next slice\n        y0 = y1\n        y0_pred = y1_pred\n\n    dice = num / denom.clamp(min=1e-8)\n    return dice.item()","metadata":{"execution":{"iopub.status.busy":"2024-11-14T13:46:47.523954Z","iopub.execute_input":"2024-11-14T13:46:47.524294Z","iopub.status.idle":"2024-11-14T13:46:47.684304Z","shell.execute_reply.started":"2024-11-14T13:46:47.524265Z","shell.execute_reply":"2024-11-14T13:46:47.683414Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nbase_path = \"/kaggle/input/blood-vessel-segmentation/train\"\ndatasets = [\"kidney_1_dense\", \"kidney_1_voi\", \"kidney_2\", \"kidney_3_sparse\"]\n\nimage_files = []\nlabels_files = []\nfor dataset in datasets:\n        print(dataset)\n        images_path = os.path.join(base_path,dataset,\"images\")\n        label_path = os.path.join(base_path,dataset,\"labels\")\n        print(images_path)\n\n        image_files.extend(sorted([os.path.join(images_path,f) for f in os.listdir(images_path) if f.endswith('.tif')]))\n        labels_files.extend(sorted([os.path.join(label_path,f) for f in os.listdir(label_path) if f.endswith('.tif')]))\n\ntrain_image_files, val_image_files, train_mask_files, val_mask_files = train_test_split(\n        image_files, labels_files, test_size=0.15, random_state=42)\nval_image_files[:5]","metadata":{"execution":{"iopub.status.busy":"2024-11-14T13:46:47.685456Z","iopub.execute_input":"2024-11-14T13:46:47.685777Z","iopub.status.idle":"2024-11-14T13:46:49.144530Z","shell.execute_reply.started":"2024-11-14T13:46:47.685753Z","shell.execute_reply":"2024-11-14T13:46:49.143560Z"},"trusted":true},"outputs":[{"name":"stdout","text":"kidney_1_dense\n/kaggle/input/blood-vessel-segmentation/train/kidney_1_dense/images\nkidney_1_voi\n/kaggle/input/blood-vessel-segmentation/train/kidney_1_voi/images\nkidney_2\n/kaggle/input/blood-vessel-segmentation/train/kidney_2/images\nkidney_3_sparse\n/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse/images\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/blood-vessel-segmentation/train/kidney_2/images/1320.tif',\n '/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse/images/0184.tif',\n '/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse/images/0153.tif',\n '/kaggle/input/blood-vessel-segmentation/train/kidney_2/images/0496.tif',\n '/kaggle/input/blood-vessel-segmentation/train/kidney_2/images/0016.tif']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"transform = A.Compose([\n    A.Resize(512,512, interpolation=cv2.INTER_NEAREST)\n])\ndataset = newDataset(\n    val_image_files, \n    val_mask_files,\n    transform=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"im, _ = dataset[0]\nplt.imshow(im)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = A.Compose([\n    A.Resize(512,512, interpolation=cv2.INTER_NEAREST)\n])\npatch = patchImage()\ntmp = patch.extract_patches(dataset[0][0])\npatches = []\nfor i in tmp:\n    patches.append(transform(image=i)['image'])\nlen(patches)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform_back = A.Compose([\n    A.Resize(768,768, interpolation=cv2.INTER_NEAREST)\n])\npatches_rs = []\nfor i in patches:\n    patches_rs.append(transform_back(image=i)['image'])\n    \nimg = patch.reconstruct_from_patches(patches_rs, dataset[0][0].shape)\nplt.imshow(img)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ssl\n\nssl._create_default_https_context = ssl._create_unverified_context\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodels = {}\n\n\nmodel = smp.UnetPlusPlus(\n        encoder_name='resnext101_32x16d',\n        encoder_weights=None,\n        decoder_attention_type=\"scse\",\n        in_channels=1\n    ).to(device)\n\nmodels['/kaggle/input/models-full/best_model_patches_resnext101_32x16d.pth'] = model\n\nmodel = smp.UnetPlusPlus(\n    encoder_name='dpn98',\n    encoder_weights=None,\n    decoder_attention_type=\"scse\",\n    in_channels=1\n).to(device)\n\nmodels['/kaggle/input/models-full/patches_dpn98.pth'] = model\n\n\n#maxvit\nmodel = smp.UnetPlusPlus(\n    encoder_name='tu-maxvit_base_tf_512',\n    encoder_weights=None,\n    decoder_attention_type=\"scse\",\n    in_channels=1\n).to(device)\nmodels[f'/kaggle/input/models_new/pytorch/default/1/{model.name}.pth'] = model\n\n#swin\nmodel = monai.networks.nets.SwinUNETR(\n    img_size=(512,512), \n    in_channels=1, \n    out_channels=1, \n    use_checkpoint=True, \n    spatial_dims=2,\n    depths=(4,4,6,8),\n    num_heads=(4,8,16,32),\n    feature_size=48,\n    drop_rate=0.05,            \n    attn_drop_rate=0.05\n).to(device)\n\nmodels['/kaggle/input/models_new/pytorch/default/1/SwinUNETR.pth'] = model\n\n#deeplabv3 \nmodel = smp.DeepLabV3Plus(\n        encoder_name='tu-seresnextaa101d_32x8d',\n        encoder_weights=None,\n        in_channels=1,\n        decoder_atrous_rates=(6,12,24),\n        decoder_channels=512\n    ).to(device)\nmodels['/kaggle/input/models_new/pytorch/default/1/DeepLabV3Plus_seresnextaa101d_32x8d.pth'] = model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_model_perf(model, criterion, criterion1, idxs, patch=False):\n    performance_evaluator = SegmentationPerformance()\n    \n    patch = patchImage()\n    transform = A.Compose([\n        A.Resize(512,512, interpolation=cv2.INTER_NEAREST)\n    ])\n\n    transform_back = A.Compose([\n        A.Resize(768,768, interpolation=cv2.INTER_NEAREST)\n    ])\n    rles = []\n       \n    with torch.no_grad():\n        for n, (images, masks) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Processing Batches\"):\n            tmp = patch.extract_patches(images[0])\n            \n            patches = []\n            for i in tmp:\n                patches.append(transform(image=i)['image'])\n\n            patches = np.array(patches)\n            patches = torch.tensor(patches, dtype=torch.float32)\n            b, h, w, c = (len(patches), *patches[0].shape, 1)\n            patches = patches.reshape(b,c,h,w).to(device)\n            \n            masks = masks.reshape(1,*(masks.shape)).to(device)\n            \n            with autocast():\n                preds = model(patches)\n\n            preds = preds.reshape(b,h,w)\n            preds_rs = []\n            for i in preds:\n                preds_rs.append(transform_back(image=i.cpu().numpy())['image'])\n\n            img = patch.reconstruct_from_patches(preds_rs, images[0].shape)\n            img = (img > 0.1).astype(float)\n            rle = rle_encode(img)\n\n            rles.append(rle)\n            img = torch.tensor(img.reshape(*(masks.shape)), dtype=torch.float32).to(device)\n            \n            with autocast():\n                loss = criterion(img, masks)\n                loss1 = criterion1(img, masks)\n\n            if n in idxs:\n                performance_evaluator.update_metrics_and_save_sample(masks, img, loss, loss1, images[0], masks[0], img[0])\n            else:\n                performance_evaluator.update_metrics_and_save_sample(masks, img, loss, loss1)\n\n            \n            \n    performance_evaluator.surface_dice = calc_surface_dice(rles)\n    \n    return performance_evaluator\n\ndef plot_model_comparisons(perfs, model_names, figsize=(10, 20)):\n    num_models = len(model_names)\n\n    if not perfs:\n        print(\"No performance data available for plotting.\")\n        return\n\n    num_samples = len(perfs[0].saved_samples)\n    plt.figure(figsize=figsize)\n\n    for i in range(num_samples):\n        image, ground_truth, _ = perfs[0].saved_samples[i]\n\n        # Plot original image\n        plt.subplot(num_samples, num_models + 2, i * (num_models + 2) + 1)\n        plt.imshow(image.squeeze(), cmap='gray')\n        plt.title('Original Image', fontsize=10)\n        plt.axis('off')\n\n        # Plot ground truth mask\n        plt.subplot(num_samples, num_models + 2, i * (num_models + 2) + 2)\n        plt.imshow(ground_truth.squeeze(), cmap='gray')\n        plt.title('Ground Truth', fontsize=10)\n        plt.axis('off')\n\n        # Plot predictions from each model\n        for j, perf in enumerate(perfs):\n            _, _, prediction = perf.saved_samples[i]\n            plt.subplot(num_samples, num_models + 2, i * (num_models + 2) + 3 + j)\n            plt.imshow(prediction.squeeze(), cmap='gray')\n            plt.title(f'Model {model_names[j]} Prediction', fontsize=5)\n            plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()    \n\ndef add_size_columns(df: pd.DataFrame):\n    \"\"\"\n    df (DataFrame): including id column, e.g., kidney_1_dense_0000\n    \"\"\"\n    widths = []\n    heights = []\n    subdirs = []\n    nums = []\n    for i, r in df.iterrows():\n        file_id = r['id']\n        subdir = file_id[:-5]    # kidney_1_dense\n        file_num = file_id[-4:]  # 0000\n\n        filename = '/kaggle/input/blood-vessel-segmentation/train/%s/images/%s.tif' % (subdir, file_num)\n        img = Image.open(filename)\n        w, h = img.size\n        widths.append(w)\n        heights.append(h)\n        subdirs.append(subdir)\n        nums.append(file_num)\n\n    df['width'] = widths\n    df['height'] = heights\n    df['image_id'] = subdirs\n    df['slice_id'] = nums\n    \n    \ndef calc_surface_dice(rles):\n    \n    ids = []\n\n    for p_img in tqdm.tqdm(val_image_files):\n        path_ = p_img.split(os.path.sep)\n        # parse the submission ID\n        dataset = path_[-3]\n        slice_id, _ = os.path.splitext(path_[-1])\n        ids.append(f\"{dataset}_{slice_id}\")\n    \n    submission = pd.DataFrame.from_dict({\n        \"id\": ids,\n        \"rle\": rles,\n    })\n\n    submission.to_csv(\"submission.csv\", index=False)\n    submission = submission.sort_values('id')\n    submission.reset_index(inplace=True)\n    submission = submission.drop('index', axis=1)\n    \n    datasets = [\"kidney_1_dense\", \"kidney_1_voi\", \"kidney_2\", \"kidney_3_sparse\"]\n\n    label = pd.read_csv('/kaggle/input/blood-vessel-segmentation/train_rles.csv')\n    label = label[label['id'].isin(submission['id'])]\n    assert len(label) > 0\n\n    # Add height, width columns\n    add_size_columns(label)\n\n    label = label.sort_values('id')\n    label.reset_index(inplace=True)\n    label = label.drop('index', axis=1)\n\n    return compute_surface_dice_score(submission, label)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:16:58.400388Z","iopub.execute_input":"2024-11-14T14:16:58.400826Z","iopub.status.idle":"2024-11-14T14:16:58.433654Z","shell.execute_reply.started":"2024-11-14T14:16:58.400794Z","shell.execute_reply":"2024-11-14T14:16:58.432538Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class BoundaryDoULossBinary(nn.Module):\n    def __init__(self):\n        super(BoundaryDoULossBinary, self).__init__()\n        # Kernel for boundary calculation, set up for 3x3 convolution\n        self.kernel = torch.Tensor([[0, 1, 0], [1, 1, 1], [0, 1, 0]]).view(1, 1, 3, 3)\n\n    def _adaptive_size(self, score, target):\n        kernel = self.kernel.to(target.device)\n        # Perform conv2d for each channel separately\n        boundary_maps = []\n        for c in range(score.size(1)):\n            Y = nn.functional.conv2d(target[:, c:c+1, :, :], kernel, padding=1)\n            Y = Y * target[:, c:c+1, :, :]\n            Y[Y == 5] = 0\n            \n            C = torch.count_nonzero(Y)\n            S = torch.count_nonzero(target[:, c:c+1, :, :])\n            smooth = 1e-5\n            alpha = 1 - (C + smooth) / (S + smooth)\n            alpha = torch.clamp(2 * alpha - 1, max=0.8)\n\n            intersect = torch.sum(score[:, c:c+1, :, :] * target[:, c:c+1, :, :])\n            y_sum = torch.sum(target[:, c:c+1, :, :] * target[:, c:c+1, :, :])\n            z_sum = torch.sum(score[:, c:c+1, :, :] * score[:, c:c+1, :, :])\n\n            loss = (z_sum + y_sum - 2 * intersect + smooth) / (z_sum + y_sum - (1 + alpha) * intersect + smooth)\n            boundary_maps.append(loss)\n        \n        return torch.stack(boundary_maps).mean()\n\n    def forward(self, inputs, target):\n        # Apply sigmoid for binary probabilities\n        inputs = torch.sigmoid(inputs)\n        target = target.float()  # Ensure target is float for multiplication\n        \n        assert inputs.size() == target.size(), f'predict {inputs.size()} & target {target.size()} shape do not match'\n        \n        return self._adaptive_size(inputs, target)\n\n        \nclass CombinedLoss(nn.Module):\n    def __init__(self, tversky_weight=1.0, focal_weight=0.9, boundary_dou_weight=0.1):\n        super(CombinedLoss, self).__init__()\n        \n        self.tversky_loss = smp.losses.TverskyLoss(mode=\"binary\", from_logits=True, alpha=0.3, beta=0.7, smooth=1e-6)\n        self.focal_loss = smp.losses.FocalLoss(mode=\"binary\")\n        self.boundary_dou_loss = BoundaryDoULossBinary()\n        \n        self.focal_weight = focal_weight\n        self.tversky_weight = tversky_weight\n        self.boundary_dou_weight = boundary_dou_weight\n\n    def forward(self, logits, targets):\n        tversky = self.tversky_loss(logits, targets)\n        focal = self.focal_loss(logits, targets)\n        boundary_dou = self.boundary_dou_loss(logits, targets)\n        \n        combined_loss = (\n            self.tversky_weight * tversky +\n            self.focal_weight * focal +\n            self.boundary_dou_weight * boundary_dou\n        )\n        \n        return combined_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:46:49.145857Z","iopub.execute_input":"2024-11-14T13:46:49.146211Z","iopub.status.idle":"2024-11-14T13:46:49.163308Z","shell.execute_reply.started":"2024-11-14T13:46:49.146178Z","shell.execute_reply":"2024-11-14T13:46:49.162267Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"criterion = CombinedLoss()\ncriterion1 = smp.losses.TverskyLoss(\n        mode='binary',         # Since it's binary segmentation\n        from_logits=True,       # Use this if your model outputs logits\n        alpha=0.3,              # Penalize false positives less\n        beta=0.7,               # Penalize false negatives more\n        smooth=1e-6             # Small smoothness constant for numerical stability\n    )\nperfs = []\nperfs_df = pd.DataFrame()\nidxs = [0, 5, 10, 15, 20, 25]#np.random.choice(range(int(len(val_image_files)/batch_size)-1), size=10, replace=False)\ntest_loader = DataLoader(dataset,batch_size=1,shuffle=False)\n\nfor model_name in list(models.keys()):\n    model = models[model_name]\n\n    state_dict = torch.load(os.path.join(base_path,model_name))\n\n    if 'model_state_dict' in state_dict:\n        state_dict = state_dict['model_state_dict']\n\n    try:\n        model.load_state_dict(state_dict)\n    except:\n        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n        model.load_state_dict(new_state_dict)\n        \n    model.eval()\n\n    perf = eval_model_perf(model, criterion, criterion1, idxs)\n    \n    perfs.append(perf)\n    tmp = perf.report()\n    tmp.insert(loc=0, column='model', value=model_name)\n\n    tmp['param_cnt'] = sum(p.numel() for p in model.parameters())\n    \n    perfs_df = pd.concat([perfs_df, tmp])\n\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"perfs_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(perfs_df.to_latex())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model_comparisons(perfs, list(models.keys()))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfilename=\"class_state.pkl\"\n\nwith open(filename, \"wb\") as file:\n    pickle.dump(perfs, file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filename=\"df_state.pkl\"\n\nwith open(filename, \"wb\") as file:\n    pickle.dump(perfs_df, file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# base_path = \"/kaggle/input/blood-vessel-segmentation/train\"2.5D","metadata":{}},{"cell_type":"code","source":"def eval_model_perf_2_5d(model, criterion, criterion1, idxs, patch=False):\n    performance_evaluator = SegmentationPerformance()\n    rles = []\n    running_iou = 0.0\n    running_dice = 0.0\n    running_acc = 0.0\n    running_rec = 0.0\n    running_pre = 0.0\n    \n    with torch.no_grad():\n        for n, (images, masks) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Processing Batches\"):\n            images = images.to(device)\n            masks = masks.to(device)\n            \n            with autocast():\n                preds = model(images)\n                loss = criterion(preds, masks)\n                loss1 = criterion1(preds, masks)\n                \n            running_dice += dice_coef(masks, preds)\n            running_iou += iou_coef(masks, preds)\n            running_acc += accuracy_coef(masks, preds)\n            running_rec += recall_coef(masks, preds)\n            running_pre += precision_coef(masks, preds)\n\n            \n            img = (preds > 0.4).cpu().to(torch.float)[0, 1, :, :]\n            \n            rle = rle_encode(img)\n            rles.append(rle)\n            img_org = images.cpu()[0, 1, :, :]\n            mask_org = masks.cpu()[0, 1, :, :]\n            \n            if n in idxs:\n                performance_evaluator.update_metrics_and_save_sample(mask_org, img, loss, loss1, img_org, mask_org, img)\n            else:\n                performance_evaluator.update_metrics_and_save_sample(mask_org, img, loss, loss1)\n                \n    print(\"iou:\", running_iou / len(test_loader))\n    print(\"dice:\", running_dice / len(test_loader))\n    print(\"acc:\", running_acc / len(test_loader))\n    print(\"rec:\", running_rec / len(test_loader))\n    print(\"pre:\", running_pre / len(test_loader))\n    \n    performance_evaluator.surface_dice = calc_surface_dice(rles)\n    return performance_evaluator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:07:50.932524Z","iopub.execute_input":"2024-11-14T14:07:50.932920Z","iopub.status.idle":"2024-11-14T14:07:50.947439Z","shell.execute_reply.started":"2024-11-14T14:07:50.932888Z","shell.execute_reply":"2024-11-14T14:07:50.946553Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from concurrent.futures import ThreadPoolExecutor, as_completed\n\nclass VolumeDataset(Dataset):\n    def __init__(\n        self, \n        data_dir, \n        kidney_orientations,  # Dictionary: { \"kidney_1_dense\": \"normal\", \"kidney_2\": \"xz\", ... }\n        target_size=1024,\n        transform=None,  # Albumentations for transformations\n        max_workers=16   # Number of parallel workers for image processing\n    ):\n        self.data_dir = data_dir\n        self.kidney_orientations = kidney_orientations\n        self.target_size = target_size\n        self.transform = transform\n        self.all_patches = []  # Store 2.5D stacks of resized images and their masks here\n\n        # Process and load all 2.5D stacks for each kidney in the specified orientations\n        self.process_all_kidneys(max_workers)\n    \n    def __len__(self):\n        return len(self.all_patches)  # Each entry is a 2.5D stack with its center slice mask\n\n    def __getitem__(self, idx):\n        # Retrieve a preprocessed 2.5D stack and center mask from all_patches\n        img_stack, mask = self.all_patches[idx]\n\n        #img_stack = self.histogram_equalization(img_stack.astype('float32') / 65535.)\n        img_stack = img_stack.astype(np.float32) / 65535.\n        mask = (mask > 0).astype(np.float32) \n\n        # Apply transformations if specified\n        if self.transform:\n            img_stack, mask = self.augment_image(img_stack, mask)\n        \n        # Convert to torch tensors\n        img_stack = torch.tensor(img_stack, dtype=torch.float32).contiguous()\n        mask = torch.tensor(mask, dtype=torch.float32).contiguous()\n        \n        return img_stack, mask\n\n    def process_all_kidneys(self, max_workers=32):\n        \"\"\"Processes all kidneys and their orientations, creates 2.5D stacks, and stores them in all_patches.\"\"\"\n        \n        def process_kidney(kidney_name):\n            orientation = 'normal'\n            if '_xz' in kidney_name:\n                orientation = 'xz'\n            elif '_yz' in kidney_name:\n                orientation = 'yz'\n            kidney = kidney_name.replace('_xz', '').replace('_yz', '')\n    \n            print(f\"Processing {kidney} with orientation: {orientation}\")\n    \n            # Load the volume and mask for each kidney and specified orientation\n            volume_path = os.path.join(self.data_dir, f\"{kidney}.mmap\")\n            mask_path = os.path.join(self.data_dir, f\"{kidney}_mask.mmap\")\n            volume, mask = self.load_volume_and_mask(volume_path, mask_path, orientation, kidney)\n    \n            # Create 2.5D stacks for the current kidney\n            self.create_stacks(volume, mask)\n    \n            # Clear memory for the current kidney\n            del volume, mask\n            torch.cuda.empty_cache()\n\n        # Execute each kidney processing in parallel\n        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = {executor.submit(process_kidney, kidney): kidney for kidney in self.kidney_orientations}\n            \n            for future in as_completed(futures):\n                kidney = futures[future]\n                try:\n                    future.result()\n                    print(f\"{kidney} processed successfully.\")\n                except Exception as exc:\n                    print(f\"{kidney} generated an exception: {exc}\")\n\n    def load_volume_and_mask(self, volume_path, mask_path, orientation, kidney):\n        \"\"\"Loads a kidney's volume and mask and applies the specified orientation.\"\"\"\n        shape = kidney_shapes[kidney] \n        volume = np.memmap(volume_path, dtype=np.uint16, mode=\"r\").reshape(shape)\n        mask = np.memmap(mask_path, dtype=np.uint8, mode=\"r\").reshape(shape)\n        \n        # Apply orientation adjustment\n        if orientation == \"xz\":\n            volume = volume.transpose((1, 2, 0))\n            mask = mask.transpose((1, 2, 0))\n        elif orientation == \"yz\":\n            volume = volume.transpose((2, 0, 1))\n            mask = mask.transpose((2, 0, 1))\n        \n        return volume, mask\n    \n    def histogram_equalization(self, image, number_bins=1024):\n        \"\"\"Applies histogram equalization to normalize the image.\"\"\"\n        image_histogram, bins = np.histogram(image.flatten(), number_bins, density=True)\n        cdf = image_histogram.cumsum()\n        cdf = (number_bins - 1) * cdf / cdf[-1]\n        image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n        return image_equalized.reshape(image.shape)\n\n    def create_stacks(self, volume, mask):\n        \"\"\"Creates 2.5D stacks of consecutive slices and corresponding masks, then appends to all_patches.\"\"\"\n        for slice_idx in range(1, volume.shape[0] - 1):\n            # Select three consecutive slices centered at slice_idx\n            img_stack = volume[slice_idx - 1:slice_idx + 2]\n            mask_stack = mask[slice_idx - 1:slice_idx + 2]  # Corresponding masks for each slice\n\n            # Resize slices and masks\n            resized_img_stack = np.stack([cv2.resize(slice_, (self.target_size, self.target_size), interpolation=cv2.INTER_LINEAR)\n                                        for slice_ in img_stack], axis=0)\n            resized_mask_stack = np.stack([cv2.resize(mask_slice, (self.target_size, self.target_size), interpolation=cv2.INTER_NEAREST)\n                                        for mask_slice in mask_stack], axis=0)\n\n            # Append resized stack and corresponding masks to all_patches\n            self.all_patches.append((resized_img_stack, resized_mask_stack))\n\n\n    def augment_image(self, image, mask):\n        \"\"\"Applies Albumentations transformations.\"\"\"\n        image_np = image.transpose(1, 2, 0) if image.ndim == 3 else image\n        mask_np = mask.transpose(1, 2, 0) if mask.ndim == 3 else mask\n\n        augmented = self.transform(image=image_np, mask=mask_np)\n        aug_image = augmented[\"image\"].transpose(2, 0, 1)\n        aug_mask = augmented[\"mask\"].transpose(2, 0, 1)\n\n        return aug_image, aug_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:52:22.495286Z","iopub.execute_input":"2024-11-14T13:52:22.495614Z","iopub.status.idle":"2024-11-14T13:52:22.521061Z","shell.execute_reply.started":"2024-11-14T13:52:22.495590Z","shell.execute_reply":"2024-11-14T13:52:22.520151Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"models = {}\ndevice = 'cuda'\nmodel = smp.Unet(\n        \"tu-maxvit_base_tf_512\",\n        in_channels=3,\n        classes=3,\n        encoder_weights=None,\n        encoder_depth=5,\n        decoder_channels=(512, 256, 128, 64, 32),\n        decoder_attention_type=\"scse\"\n    ).to(device)\n\nmodels['/kaggle/input/models_2.5d/pytorch/default/1/u-maxvit_base_tf_512.pth'] = model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:52:22.522158Z","iopub.execute_input":"2024-11-14T13:52:22.522434Z","iopub.status.idle":"2024-11-14T13:52:25.865170Z","shell.execute_reply.started":"2024-11-14T13:52:22.522402Z","shell.execute_reply":"2024-11-14T13:52:25.864336Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"len(sorted(os.listdir('/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse/images'))[1:-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:33:04.585334Z","iopub.execute_input":"2024-11-14T14:33:04.585773Z","iopub.status.idle":"2024-11-14T14:33:04.597011Z","shell.execute_reply.started":"2024-11-14T14:33:04.585741Z","shell.execute_reply":"2024-11-14T14:33:04.595998Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"1033"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def calc_surface_dice(rles):\n    \n    ids = []\n    a = sorted(os.listdir('/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse/images'))[1:-1]\n    for p_img in tqdm.tqdm(a):\n        p_img = os.path.join('/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse/images', p_img)\n        path_ = p_img.split(os.path.sep)\n        # parse the submission ID\n        dataset = path_[-3]\n        slice_id, _ = os.path.splitext(path_[-1])\n        ids.append(f\"{dataset}_{slice_id}\")\n\n    print(len(ids), len(rles))\n    submission = pd.DataFrame.from_dict({\n        \"id\": ids,\n        \"rle\": rles,\n    })\n\n    submission.to_csv(\"submission.csv\", index=False)\n    submission = submission.sort_values('id')\n    submission.reset_index(inplace=True)\n    submission = submission.drop('index', axis=1)\n    \n    datasets = [\"kidney_3_sparse\"]\n\n    label = pd.read_csv('/kaggle/input/blood-vessel-segmentation/train_rles.csv')\n    label = label[label['id'].isin(submission['id'])]\n    assert len(label) > 0\n\n    # Add height, width columns\n    add_size_columns(label)\n\n    label = label.sort_values('id')\n    label.reset_index(inplace=True)\n    label = label.drop('index', axis=1)\n\n    return compute_surface_dice_score(submission, label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:33:42.279756Z","iopub.execute_input":"2024-11-14T14:33:42.280749Z","iopub.status.idle":"2024-11-14T14:33:42.292308Z","shell.execute_reply.started":"2024-11-14T14:33:42.280709Z","shell.execute_reply":"2024-11-14T14:33:42.291207Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"kidney_shapes = {\n    \"kidney_1_dense\": (2279, 1303, 912), \n    \"kidney_1_voi\": (1397, 1928, 1928), \n    \"kidney_2\": (2217, 1041, 1511), \n    \"kidney_3\": (1035, 1706, 1510), \n    \"kidney_3_dense\": (501, 1706, 1510),\n    \"kidney_3_sparse\": (1035, 1706, 1510),\n}\n\nval_orientations = [\"kidney_3_sparse\"]\npath = '/kaggle/working/mmap'\nimage_size = 1024\n\ndataset = VolumeDataset(\n    data_dir=path,\n    kidney_orientations=val_orientations,\n    target_size=image_size,\n    transform=A.Compose([A.Resize(image_size, image_size, interpolation=cv2.INTER_NEAREST)])\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:52:25.877260Z","iopub.execute_input":"2024-11-14T13:52:25.877584Z","iopub.status.idle":"2024-11-14T13:52:39.528944Z","shell.execute_reply.started":"2024-11-14T13:52:25.877551Z","shell.execute_reply":"2024-11-14T13:52:39.528014Z"}},"outputs":[{"name":"stdout","text":"Processing kidney_3_sparse with orientation: normal\nkidney_3_sparse processed successfully.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"criterion = CombinedLoss()\ncriterion1 = smp.losses.TverskyLoss(\n        mode='binary',         # Since it's binary segmentation\n        from_logits=True,       # Use this if your model outputs logits\n        alpha=0.3,              # Penalize false positives less\n        beta=0.7,               # Penalize false negatives more\n        smooth=1e-6             # Small smoothness constant for numerical stability\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:52:39.529935Z","iopub.execute_input":"2024-11-14T13:52:39.530201Z","iopub.status.idle":"2024-11-14T13:52:39.535870Z","shell.execute_reply.started":"2024-11-14T13:52:39.530178Z","shell.execute_reply":"2024-11-14T13:52:39.534919Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nperfs = []\nperfs_df = pd.DataFrame()\nidxs = [0, 100, 300, 555, 700, 825]#np.random.choice(range(int(len(val_image_files)/batch_size)-1), size=10, replace=False)\ntest_loader = DataLoader(dataset,batch_size=1,shuffle=False)\nbase_path = \"/\"\nfor model_name in list(models.keys()):\n    model = models[model_name]\n\n    state_dict = torch.load(os.path.join(base_path,model_name))\n\n    if 'model_state_dict' in state_dict:\n        print(state_dict['val_loss'])\n        state_dict = state_dict['model_state_dict']\n\n    try:\n        model.load_state_dict(state_dict)\n    except:\n        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n        model.load_state_dict(new_state_dict)\n        \n    model.eval()\n    \n    perf = eval_model_perf_2_5d(model, criterion, criterion1, idxs)\n    \n    perfs.append(perf)\n    tmp = perf.report()\n    tmp.insert(loc=0, column='model', value=model_name)\n\n    tmp['param_cnt'] = sum(p.numel() for p in model.parameters())\n    \n    perfs_df = pd.concat([perfs_df, tmp])\n\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:33:53.412920Z","iopub.execute_input":"2024-11-14T14:33:53.413286Z","iopub.status.idle":"2024-11-14T14:41:12.610495Z","shell.execute_reply.started":"2024-11-14T14:33:53.413256Z","shell.execute_reply":"2024-11-14T14:41:12.609439Z"}},"outputs":[{"name":"stdout","text":"tensor(0.6361, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches: 100%|██████████| 1033/1033 [06:55<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"iou: tensor(0.6334, device='cuda:0')\ndice: tensor(0.7449, device='cuda:0')\nacc: tensor(0.9989, device='cuda:0')\nrec: tensor(0.8547, device='cuda:0')\npre: tensor(0.7392, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1033/1033 [00:00<00:00, 156817.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"1033 1033\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"models = {}\n\n#unetplusplus-tu-maxvit_rmlp_base_rw_384.pth\nmodel = smp.UnetPlusPlus(\n        \"tu-maxvit_rmlp_base_rw_384\",\n        in_channels=3,\n        classes=3,\n        encoder_weights=None,\n        encoder_depth=4,\n        decoder_channels=(256, 128, 64, 32),\n        decoder_attention_type=\"scse\"\n    ).to(device)\n\nmodels['/kaggle/input/models_2.5d/pytorch/default/1/unetplusplus-tu-maxvit_rmlp_base_rw_384.pth'] = model\n\n#unetplusplus-tu-maxvit_rmlp_base_rw_384_large.pth\nmodel = smp.UnetPlusPlus(\n        \"tu-maxvit_rmlp_base_rw_384\",\n        in_channels=3,\n        classes=3,\n        encoder_weights=None,\n        encoder_depth=5,\n        decoder_channels=(512, 256, 128, 64, 32),\n        decoder_attention_type=\"scse\"\n    ).to(device)\n\nmodels['/kaggle/input/models_2.5d/pytorch/default/1/unetplusplus-tu-maxvit_rmlp_base_rw_384_large.pth'] = model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:41:12.612448Z","iopub.execute_input":"2024-11-14T14:41:12.612760Z","iopub.status.idle":"2024-11-14T14:41:23.182286Z","shell.execute_reply.started":"2024-11-14T14:41:12.612735Z","shell.execute_reply":"2024-11-14T14:41:23.181457Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"image_size = 768\nkidney_shapes = {\n    \"kidney_1_dense\": (2279, 1303, 912), \n    \"kidney_1_voi\": (1397, 1928, 1928), \n    \"kidney_2\": (2217, 1041, 1511), \n    \"kidney_3\": (1035, 1706, 1510), \n    \"kidney_3_dense\": (501, 1706, 1510),\n    \"kidney_3_sparse\": (1035, 1706, 1510),\n}\n\nval_orientations = [\"kidney_3_sparse\"]\npath = '/kaggle/working/mmap'\n\ndataset = VolumeDataset(\n    data_dir=path,\n    kidney_orientations=val_orientations,\n    target_size=image_size,\n    transform=A.Compose([A.Resize(image_size, image_size, interpolation=cv2.INTER_NEAREST)])\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:41:23.183391Z","iopub.execute_input":"2024-11-14T14:41:23.183688Z","iopub.status.idle":"2024-11-14T14:42:11.414007Z","shell.execute_reply.started":"2024-11-14T14:41:23.183662Z","shell.execute_reply":"2024-11-14T14:42:11.413050Z"}},"outputs":[{"name":"stdout","text":"Processing kidney_3_sparse with orientation: normal\nkidney_3_sparse processed successfully.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def dice_coef(y_true, y_pred, thr=0.4, dim=(2,3), epsilon=0.001):\n    y_true = y_true.to(torch.float32)\n    y_pred = (y_pred>thr).to(torch.float32)\n    inter = (y_true*y_pred).sum(dim=dim)\n    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(0, 1))\n    return dice\n\n\ndef iou_coef(y_true, y_pred, thr=0.4, dim=(2,3), epsilon=0.001):\n    y_true = y_true.to(torch.float32)\n    y_pred = (y_pred>thr).to(torch.float32)\n    inter = (y_true*y_pred).sum(dim=dim)\n    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(0, 1))\n    return iou\n\ndef accuracy_coef(y_true, y_pred, thr=0.4, dim=(2,3), epsilon=0.001):\n    y_true = y_true.to(torch.float32)\n    y_pred = (y_pred > thr).to(torch.float32)\n    correct_predictions = (y_true == y_pred).sum(dim=dim)\n    total_pixels = torch.tensor(y_true.shape[2] * y_true.shape[3], device=y_true.device)  # H x W\n    accuracy = (correct_predictions / (total_pixels + epsilon)).mean(dim=(0, 1))\n    return accuracy\n\ndef recall_coef(y_true, y_pred, thr=0.4, dim=(2,3), epsilon=0.001):\n    y_true = y_true.to(torch.float32)\n    y_pred = (y_pred > thr).to(torch.float32)\n    true_positive = (y_true * y_pred).sum(dim=dim)\n    actual_positive = y_true.sum(dim=dim)\n    recall = ((true_positive + epsilon) / (actual_positive + epsilon)).mean(dim=(0, 1))\n    return recall\n\ndef precision_coef(y_true, y_pred, thr=0.4, dim=(2,3), epsilon=0.001):\n    y_true = y_true.to(torch.float32)\n    y_pred = (y_pred > thr).to(torch.float32)\n    true_positive = (y_true * y_pred).sum(dim=dim)\n    predicted_positive = y_pred.sum(dim=dim)\n    precision = ((true_positive + epsilon) / (predicted_positive + epsilon)).mean(dim=(0, 1))\n    return precision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:42:11.416884Z","iopub.execute_input":"2024-11-14T14:42:11.417169Z","iopub.status.idle":"2024-11-14T14:42:11.432793Z","shell.execute_reply.started":"2024-11-14T14:42:11.417143Z","shell.execute_reply":"2024-11-14T14:42:11.431864Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import tqdm\nidxs = [0, 100, 300, 555, 700, 825]#np.random.choice(range(int(len(val_image_files)/batch_size)-1), size=10, replace=False)\ntest_loader = DataLoader(dataset,batch_size=1,shuffle=False)\nbase_path = '/'\nfor model_name in list(models.keys()):\n    model = models[model_name]\n\n    state_dict1 = torch.load(os.path.join(base_path,model_name))\n\n    if 'model_state_dict' in state_dict1:\n        state_dict = state_dict1['model_state_dict']\n        print(state_dict1[\"val_loss\"])\n        \n    try:\n        model.load_state_dict(state_dict)\n    except:\n        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n        model.load_state_dict(new_state_dict)\n        \n    model.eval()\n\n    perf = eval_model_perf_2_5d(model, criterion, criterion1, idxs)\n    \n    perfs.append(perf)\n    tmp = perf.report()\n    tmp.insert(loc=0, column='model', value=model_name)\n\n    tmp['param_cnt'] = sum(p.numel() for p in model.parameters())\n    \n    perfs_df = pd.concat([perfs_df, tmp])\n\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:42:11.433810Z","iopub.execute_input":"2024-11-14T14:42:11.434096Z","iopub.status.idle":"2024-11-14T14:51:43.868868Z","shell.execute_reply.started":"2024-11-14T14:42:11.434071Z","shell.execute_reply":"2024-11-14T14:51:43.868018Z"}},"outputs":[{"name":"stdout","text":"0.2761238418720864\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches: 100%|██████████| 1033/1033 [04:03<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"iou: tensor(0.7412, device='cuda:0')\ndice: tensor(0.8241, device='cuda:0')\nacc: tensor(0.9994, device='cuda:0')\nrec: tensor(0.8915, device='cuda:0')\npre: tensor(0.8091, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1033/1033 [00:00<00:00, 155785.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"1033 1033\ntensor(0.7405, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches: 100%|██████████| 1033/1033 [04:37<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"iou: tensor(0.7420, device='cuda:0')\ndice: tensor(0.8244, device='cuda:0')\nacc: tensor(0.9994, device='cuda:0')\nrec: tensor(0.8787, device='cuda:0')\npre: tensor(0.8241, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1033/1033 [00:00<00:00, 162982.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"1033 1033\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"perfs_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:51:43.870085Z","iopub.execute_input":"2024-11-14T14:51:43.870362Z","iopub.status.idle":"2024-11-14T14:51:43.891581Z","shell.execute_reply.started":"2024-11-14T14:51:43.870338Z","shell.execute_reply":"2024-11-14T14:51:43.890674Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                               model  Precision    Recall  \\\n0  /kaggle/input/models_2.5d/pytorch/default/1/u-...   0.813902  0.586269   \n0  /kaggle/input/models_2.5d/pytorch/default/1/un...   0.657002  0.790477   \n0  /kaggle/input/models_2.5d/pytorch/default/1/un...   0.692457  0.765262   \n\n   Accuracy  Dice Coefficient       IoU  Average Loss  Average Loss1  \\\n0  0.999228          0.673018  0.569333      0.262259       0.198064   \n0  0.999290          0.705127  0.619861      0.185785       0.149569   \n0  0.999353          0.715590  0.632283      0.184338       0.147855   \n\n   Avg Surface Dice  param_cnt  \n0          0.001560  129426937  \n0          0.000711   81621347  \n0          0.000648  129212693  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Accuracy</th>\n      <th>Dice Coefficient</th>\n      <th>IoU</th>\n      <th>Average Loss</th>\n      <th>Average Loss1</th>\n      <th>Avg Surface Dice</th>\n      <th>param_cnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/models_2.5d/pytorch/default/1/u-...</td>\n      <td>0.813902</td>\n      <td>0.586269</td>\n      <td>0.999228</td>\n      <td>0.673018</td>\n      <td>0.569333</td>\n      <td>0.262259</td>\n      <td>0.198064</td>\n      <td>0.001560</td>\n      <td>129426937</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/models_2.5d/pytorch/default/1/un...</td>\n      <td>0.657002</td>\n      <td>0.790477</td>\n      <td>0.999290</td>\n      <td>0.705127</td>\n      <td>0.619861</td>\n      <td>0.185785</td>\n      <td>0.149569</td>\n      <td>0.000711</td>\n      <td>81621347</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/models_2.5d/pytorch/default/1/un...</td>\n      <td>0.692457</td>\n      <td>0.765262</td>\n      <td>0.999353</td>\n      <td>0.715590</td>\n      <td>0.632283</td>\n      <td>0.184338</td>\n      <td>0.147855</td>\n      <td>0.000648</td>\n      <td>129212693</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"print(perfs_df.to_latex())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:51:43.892547Z","iopub.execute_input":"2024-11-14T14:51:43.892804Z","iopub.status.idle":"2024-11-14T14:51:44.122677Z","shell.execute_reply.started":"2024-11-14T14:51:43.892781Z","shell.execute_reply":"2024-11-14T14:51:44.121719Z"}},"outputs":[{"name":"stdout","text":"\\begin{tabular}{llrrrrrrrrr}\n\\toprule\n & model & Precision & Recall & Accuracy & Dice Coefficient & IoU & Average Loss & Average Loss1 & Avg Surface Dice & param_cnt \\\\\n\\midrule\n0 & /kaggle/input/models_2.5d/pytorch/default/1/u-maxvit_base_tf_512.pth & 0.813902 & 0.586269 & 0.999228 & 0.673018 & 0.569333 & 0.262259 & 0.198064 & 0.001560 & 129426937 \\\\\n0 & /kaggle/input/models_2.5d/pytorch/default/1/unetplusplus-tu-maxvit_rmlp_base_rw_384.pth & 0.657002 & 0.790477 & 0.999290 & 0.705127 & 0.619861 & 0.185785 & 0.149569 & 0.000711 & 81621347 \\\\\n0 & /kaggle/input/models_2.5d/pytorch/default/1/unetplusplus-tu-maxvit_rmlp_base_rw_384_large.pth & 0.692457 & 0.765262 & 0.999353 & 0.715590 & 0.632283 & 0.184338 & 0.147855 & 0.000648 & 129212693 \\\\\n\\bottomrule\n\\end{tabular}\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"plot_model_comparisons(perfs, list(models.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:51:44.124019Z","iopub.execute_input":"2024-11-14T14:51:44.125303Z","iopub.status.idle":"2024-11-14T14:51:45.083017Z","shell.execute_reply.started":"2024-11-14T14:51:44.125263Z","shell.execute_reply":"2024-11-14T14:51:45.081898Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_model_comparisons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[27], line 89\u001b[0m, in \u001b[0;36mplot_model_comparisons\u001b[0;34m(perfs, model_names, figsize)\u001b[0m\n\u001b[1;32m     87\u001b[0m         plt\u001b[38;5;241m.\u001b[39msubplot(num_samples, num_models \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, i \u001b[38;5;241m*\u001b[39m (num_models \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m j)\n\u001b[1;32m     88\u001b[0m         plt\u001b[38;5;241m.\u001b[39mimshow(prediction\u001b[38;5;241m.\u001b[39msqueeze(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m         plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Prediction\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     90\u001b[0m         plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     92\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x2000 with 5 Axes>","image/png":"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"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"filename=\"class_state25d.pkl\"\n\nwith open(filename, \"wb\") as file:\n    pickle.dump(perfs, file)\n\nfilename=\"df_state25d.pkl\"\n\nwith open(filename, \"wb\") as file:\n    pickle.dump(perfs_df, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:51:45.083822Z","iopub.status.idle":"2024-11-14T14:51:45.084148Z","shell.execute_reply.started":"2024-11-14T14:51:45.083987Z","shell.execute_reply":"2024-11-14T14:51:45.084000Z"}},"outputs":[],"execution_count":null}]}