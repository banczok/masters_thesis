{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61446,"databundleVersionId":6962461,"sourceType":"competition"},{"sourceId":6988238,"sourceType":"datasetVersion","datasetId":4016367},{"sourceId":7047232,"sourceType":"datasetVersion","datasetId":4009913},{"sourceId":7047382,"sourceType":"datasetVersion","datasetId":4055366},{"sourceId":7070094,"sourceType":"datasetVersion","datasetId":4071363},{"sourceId":7073418,"sourceType":"datasetVersion","datasetId":4072639},{"sourceId":7205725,"sourceType":"datasetVersion","datasetId":4055374},{"sourceId":7224027,"sourceType":"datasetVersion","datasetId":4181456},{"sourceId":7258395,"sourceType":"datasetVersion","datasetId":4206264},{"sourceId":7304002,"sourceType":"datasetVersion","datasetId":4237589},{"sourceId":7311364,"sourceType":"datasetVersion","datasetId":4242527},{"sourceId":7315836,"sourceType":"datasetVersion","datasetId":4245320},{"sourceId":7321059,"sourceType":"datasetVersion","datasetId":4245329},{"sourceId":7350318,"sourceType":"datasetVersion","datasetId":4266569},{"sourceId":7354364,"sourceType":"datasetVersion","datasetId":4271235},{"sourceId":7354626,"sourceType":"datasetVersion","datasetId":4271108},{"sourceId":7359335,"sourceType":"datasetVersion","datasetId":4272204},{"sourceId":7367471,"sourceType":"datasetVersion","datasetId":4279640},{"sourceId":7373862,"sourceType":"datasetVersion","datasetId":4284491},{"sourceId":7373875,"sourceType":"datasetVersion","datasetId":4284499},{"sourceId":7374032,"sourceType":"datasetVersion","datasetId":4284599},{"sourceId":7380046,"sourceType":"datasetVersion","datasetId":4288797},{"sourceId":7381525,"sourceType":"datasetVersion","datasetId":4289816},{"sourceId":7390847,"sourceType":"datasetVersion","datasetId":4296436},{"sourceId":7434865,"sourceType":"datasetVersion","datasetId":4322047},{"sourceId":7460678,"sourceType":"datasetVersion","datasetId":4342221},{"sourceId":7495928,"sourceType":"datasetVersion","datasetId":4364681},{"sourceId":7612672,"sourceType":"datasetVersion","datasetId":4433048},{"sourceId":150248402,"sourceType":"kernelVersion"},{"sourceId":150386064,"sourceType":"kernelVersion"},{"sourceId":207367131,"sourceType":"kernelVersion"},{"sourceId":165799,"sourceType":"modelInstanceVersion","modelInstanceId":141071,"modelId":163679},{"sourceId":166890,"sourceType":"modelInstanceVersion","modelInstanceId":142006,"modelId":164583},{"sourceId":166902,"sourceType":"modelInstanceVersion","modelInstanceId":142006,"modelId":164583}],"dockerImageVersionId":30580,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prepare","metadata":{}},{"cell_type":"code","source":"!python -m pip install --no-index --find-links=/kaggle/input/pip-tritone triton==2.1.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T11:01:03.059383Z","iopub.execute_input":"2024-11-16T11:01:03.060138Z","iopub.status.idle":"2024-11-16T11:01:19.478624Z","shell.execute_reply.started":"2024-11-16T11:01:03.060104Z","shell.execute_reply":"2024-11-16T11:01:19.477504Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/pip-tritone\nProcessing /kaggle/input/pip-tritone/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.1.0) (3.12.2)\nInstalling collected packages: triton\nSuccessfully installed triton-2.1.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!python -m pip install --no-index --find-links=/kaggle/input/pip-tritone torch==2.1.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T11:01:19.480634Z","iopub.execute_input":"2024-11-16T11:01:19.480937Z","iopub.status.idle":"2024-11-16T11:02:46.034552Z","shell.execute_reply.started":"2024-11-16T11:01:19.480909Z","shell.execute_reply":"2024-11-16T11:02:46.033278Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/pip-tritone\nProcessing /kaggle/input/pip-tritone/torch-2.1.1+cu118-cp310-cp310-linux_x86_64.whl\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (2023.10.0)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.1) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.1) (1.3.0)\nInstalling collected packages: torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0\n    Uninstalling torch-2.0.0:\n      Successfully uninstalled torch-2.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.1.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.1.1+cu118\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q /kaggle/input/pip-input/other/default/1/connected_components_3d-3.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T11:02:46.036485Z","iopub.execute_input":"2024-11-16T11:02:46.036922Z","iopub.status.idle":"2024-11-16T11:03:18.176996Z","shell.execute_reply.started":"2024-11-16T11:02:46.036877Z","shell.execute_reply":"2024-11-16T11:03:18.175882Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install -q /kaggle/input/pip-input/other/default/1/einops-0.7.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T11:03:18.179469Z","iopub.execute_input":"2024-11-16T11:03:18.179845Z","iopub.status.idle":"2024-11-16T11:03:50.036611Z","shell.execute_reply.started":"2024-11-16T11:03:18.179811Z","shell.execute_reply":"2024-11-16T11:03:50.035485Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install -q /kaggle/input/pip-download-for-segmentation-models-pytorch/munch-4.0.0-py2.py3-none-any.whl\n!pip install -q /kaggle/input/pip-download-for-segmentation-models-pytorch/pretrainedmodels-0.7.4.tar.gz\n!pip install -q /kaggle/input/pip-download-for-segmentation-models-pytorch/efficientnet_pytorch-0.7.1.tar.gz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-16T11:03:50.038284Z","iopub.execute_input":"2024-11-16T11:03:50.038610Z","iopub.status.idle":"2024-11-16T11:05:30.153799Z","shell.execute_reply.started":"2024-11-16T11:03:50.038578Z","shell.execute_reply":"2024-11-16T11:05:30.152597Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T11:05:30.155182Z","iopub.execute_input":"2024-11-16T11:05:30.155457Z","iopub.status.idle":"2024-11-16T11:05:43.494826Z","shell.execute_reply.started":"2024-11-16T11:05:30.155428Z","shell.execute_reply":"2024-11-16T11:05:43.493532Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/pip-download-for-segmentation-models-pytorch\nProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/segmentation_models_pytorch-0.3.3-py3-none-any.whl\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\nProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/timm-0.9.2-py3-none-any.whl (from segmentation-models-pytorch)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.1+cu118)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.10.0)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nInstalling collected packages: timm, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.9.10\n    Uninstalling timm-0.9.10:\n      Successfully uninstalled timm-0.9.10\nSuccessfully installed segmentation-models-pytorch-0.3.3 timm-0.9.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile /opt/conda/lib/python3.10/site-packages/triton/common/build.py\n# https://github.com/openai/triton/issues/2507\n\nimport contextlib\nimport functools\nimport io\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport sysconfig\n\n\nimport setuptools\n\n\n# TODO: is_hip shouldn't be here\ndef is_hip():\n    import torch\n    return torch.version.hip is not None\n\n\n@functools.lru_cache()\ndef libcuda_dirs():\n    libs = subprocess.check_output([\"ldconfig\", \"-p\"]).decode()\n    # each line looks like the following:\n    # libcuda.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libcuda.so.1\n    locs = [line.split()[-1] for line in libs.splitlines() if \"libcuda.so\" in line]\n    dirs = [os.path.dirname(loc) for loc in locs]\n    env_ld_library_path = os.getenv(\"LD_LIBRARY_PATH\")\n    if env_ld_library_path and not dirs:\n        dirs = [dir for dir in env_ld_library_path.split(\":\") if os.path.exists(os.path.join(dir, \"libcuda.so\"))]\n    msg = 'libcuda.so cannot found!\\n'\n    if locs:\n        msg += 'Possible files are located at %s.' % str(locs)\n        msg += 'Please create a symlink of libcuda.so to any of the file.'\n    assert any(os.path.exists(os.path.join(path, 'libcuda.so')) for path in dirs), msg\n    return dirs\n\n\n@functools.lru_cache()\ndef rocm_path_dir():\n    return os.getenv(\"ROCM_PATH\", default=\"/opt/rocm\")\n\n\n@contextlib.contextmanager\ndef quiet():\n    old_stdout, old_stderr = sys.stdout, sys.stderr\n    sys.stdout, sys.stderr = io.StringIO(), io.StringIO()\n    try:\n        yield\n    finally:\n        sys.stdout, sys.stderr = old_stdout, old_stderr\n\n\n@functools.lru_cache()\ndef cuda_include_dir():\n    base_dir = os.path.join(os.path.dirname(__file__), os.path.pardir)\n    cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n    return os.path.join(cuda_path, \"include\")\n\n\ndef _build(name, src, srcdir):\n    if is_hip():\n        hip_lib_dir = os.path.join(rocm_path_dir(), \"lib\")\n        hip_include_dir = os.path.join(rocm_path_dir(), \"include\")\n    else:\n        cuda_lib_dirs = libcuda_dirs()\n        cu_include_dir = cuda_include_dir()\n    suffix = sysconfig.get_config_var('EXT_SUFFIX')\n    so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n    # try to avoid setuptools if possible\n    cc = os.environ.get(\"CC\")\n    if cc is None:\n        # TODO: support more things here.\n        clang = shutil.which(\"clang\")\n        gcc = shutil.which(\"gcc\")\n        cc = gcc if gcc is not None else clang\n        if cc is None:\n            raise RuntimeError(\"Failed to find C compiler. Please specify via CC environment variable.\")\n    # This function was renamed and made public in Python 3.10\n    if hasattr(sysconfig, 'get_default_scheme'):\n        scheme = sysconfig.get_default_scheme()\n    else:\n        scheme = sysconfig._get_default_scheme()\n    # 'posix_local' is a custom scheme on Debian. However, starting Python 3.10, the default install\n    # path changes to include 'local'. This change is required to use triton with system-wide python.\n    if scheme == 'posix_local':\n        scheme = 'posix_prefix'\n    py_include_dir = sysconfig.get_paths(scheme=scheme)[\"include\"]\n\n    if is_hip():\n        ret = subprocess.check_call([cc, src, f\"-I{hip_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", f\"-L{hip_lib_dir}\", \"-lamdhip64\", \"-o\", so])\n    else:\n        cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]\n        cc_cmd += [f\"-L{dir}\" for dir in cuda_lib_dirs]\n        ret = subprocess.check_call(cc_cmd)\n\n    if ret == 0:\n        return so\n    # fallback on setuptools\n    extra_compile_args = []\n    library_dirs = cuda_lib_dirs\n    include_dirs = [srcdir, cu_include_dir]\n    libraries = ['cuda']\n    # extra arguments\n    extra_link_args = []\n    # create extension module\n    ext = setuptools.Extension(\n        name=name,\n        language='c',\n        sources=[src],\n        include_dirs=include_dirs,\n        extra_compile_args=extra_compile_args + ['-O3'],\n        extra_link_args=extra_link_args,\n        library_dirs=library_dirs,\n        libraries=libraries,\n    )\n    # build extension module\n    args = ['build_ext']\n    args.append('--build-temp=' + srcdir)\n    args.append('--build-lib=' + srcdir)\n    args.append('-q')\n    args = dict(\n        name=name,\n        ext_modules=[ext],\n        script_args=args,\n    )\n    with quiet():\n        setuptools.setup(**args)\n    return so","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-16T11:05:43.496843Z","iopub.execute_input":"2024-11-16T11:05:43.497302Z","iopub.status.idle":"2024-11-16T11:05:43.509761Z","shell.execute_reply.started":"2024-11-16T11:05:43.497254Z","shell.execute_reply":"2024-11-16T11:05:43.508690Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting /opt/conda/lib/python3.10/site-packages/triton/common/build.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"#INTER=cv2.INTER_NEAREST cv2.INTER_LANCZOS4\n#IMAGE_SIZE=768#3072\n#z|y|x\n\n#1536\n#1920\n#2304\n#2688\n#3072","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T11:05:43.511026Z","iopub.execute_input":"2024-11-16T11:05:43.511356Z","iopub.status.idle":"2024-11-16T11:05:43.524230Z","shell.execute_reply.started":"2024-11-16T11:05:43.511329Z","shell.execute_reply":"2024-11-16T11:05:43.523248Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"%%writefile inference.sh\n#!/bin/bash \n\nSEED=42\nBACKBONE='tu-maxvit_rmlp_base_rw_384'\nCKPT_PATH=\"/kaggle/input/models_2.5d/pytorch/default/1/unetplusplus-tu-maxvit_rmlp_base_rw_384.pth\"\nIN_CHANNELS=3\nNUM_CLASSES=3\nIMAGE_SIZE=3072\nBATCH_SIZE=8\nTHRESHOLD=0.4\nAXIS=\"z|y|x\"\nFLIP=5\nROT=3\n\n\nfor group in kidney_3_sparse; do\n    python inference.py \\\n    --seed $SEED \\\n    --group $group \\\n    --backbone $BACKBONE \\\n    --ckpt_path $CKPT_PATH \\\n    --in_channels $IN_CHANNELS \\\n    --num_classes $NUM_CLASSES \\\n    --image_size $IMAGE_SIZE \\\n    --batch_size $BATCH_SIZE \\\n    --axis $AXIS \\\n    --flip $FLIP \\\n    --rot $ROT \\\n    --overlap \\\n    --threshold $THRESHOLD\ndone","metadata":{"execution":{"iopub.status.busy":"2024-11-16T11:05:43.525719Z","iopub.execute_input":"2024-11-16T11:05:43.526028Z","iopub.status.idle":"2024-11-16T11:05:43.535813Z","shell.execute_reply.started":"2024-11-16T11:05:43.525998Z","shell.execute_reply":"2024-11-16T11:05:43.534875Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Writing inference.sh\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%writefile inference.py\n\nimport os\nimport sys\nimport cv2\nimport cc3d\nimport timm\nimport shutil\nimport argparse\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport albumentations as A\nfrom functools import partial\nfrom collections import deque\nfrom glob import glob\nfrom itertools import starmap\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\n\nsys.path.append(\"/kaggle/input/segmentation-models-pytorch-extra-stem-2-5d\")\nimport segmentation_models_pytorch as smp\n\n############################################### helper functions ##################################################\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    if rle=='':\n        rle = '1 0'\n    return rle\n\ndef is_dist_avail_and_initialized():\n    if not dist.is_available():\n        return False\n    if not dist.is_initialized():\n        return False\n    return True\n\n\ndef get_world_size():\n    if not is_dist_avail_and_initialized():\n        return 1\n    return dist.get_world_size()\n\n\ndef get_rank():\n    if not is_dist_avail_and_initialized():\n        return 0\n    return dist.get_rank()\n\n\ndef is_main_process():\n    return get_rank() == 0\n\n\ndef build_model(backbone, in_channels, num_classes):\n    model = smp.UnetPlusPlus(\n        \"tu-maxvit_rmlp_base_rw_384\",\n        in_channels=3,\n        classes=3,\n        encoder_weights=None,\n        encoder_depth=4,\n        decoder_channels=(256, 128, 64, 32),\n        decoder_attention_type=\"scse\"\n    )\n    return model\n\n\ndef filter_checkpoint(state_dict):\n    new_state_dict = {}\n    for k, v in state_dict.items():\n        new_state_dict[k.replace(\"module.\", \"\")] = v\n    return new_state_dict\n\n\ndef load_model(backbone, in_channels, num_classes, path):\n    model = build_model(backbone, in_channels, num_classes)\n    state_dict = torch.load(path, map_location=\"cpu\")['model_state_dict']\n    state_dict = filter_checkpoint(state_dict)\n    model.load_state_dict(state_dict)\n    model.eval()\n    return model\n\n\nclass Ensemble(object):\n    def __init__(self, backbone, in_channels, num_classes, ckpts, device):\n        self.models = []\n        for ckpt_path in ckpts:\n            model = load_model(backbone, in_channels, num_classes, ckpt_path).to(device)\n            model = torch.compile(model)\n            self.models.append(model)\n            \n    def __call__(self, x):\n        out = None\n        for model in self.models:\n            if out is None:\n                out = model(x).sigmoid()\n            else:\n                out += model(x).sigmoid()\n        out /= len(self.models)\n        return out\n\n\nclass InferenceDataset(torch.utils.data.Dataset):\n    \n    axis2dim = {\"z\": 0, \"y\": 1, \"x\": 2}\n    \n    def __init__(self, volume_path, volume_shape, local_rank, world_size, in_channels=3, image_size=512, axis=\"z\"):\n        self.volume_path = volume_path\n        self.volume_shape = volume_shape\n        self.axis = axis\n        self.in_channels = in_channels\n        self.image_size = image_size\n        block = self.volume_shape[self.axis2dim[self.axis]] // world_size\n        if local_rank < world_size-1:\n            self.indexs = range(self.volume_shape[self.axis2dim[self.axis]])[local_rank*block:(local_rank+1)*block]\n        else:\n            self.indexs = range(self.volume_shape[self.axis2dim[self.axis]])[local_rank*block:]\n        \n    def __len__(self):\n        return len(self.indexs)\n    \n    def load_image(self, idx):\n        idx = self.indexs[idx]\n        volume = np.memmap(self.volume_path, shape=self.volume_shape, dtype=np.uint16, mode=\"r\")\n        idxs = np.clip(range(idx-self.in_channels//2, idx+self.in_channels//2+1), 0, self.volume_shape[self.axis2dim[self.axis]]-1)\n        #print(idxs)\n        if self.axis == \"z\":\n            image =  volume[idxs].transpose(1, 2, 0)\n        elif self.axis == \"x\":\n            image =  volume[:, :, idxs]\n        else:\n            image =  volume[:, idxs, :].transpose(0, 2, 1)\n        image = image.astype(np.float32)\n        image = image / 65535.0\n        return image\n    \n    def __getitem__(self, idx):\n        image = self.load_image(idx)\n        orig_size = image.shape\n        # LANCZOS4 is slighter better than bilinear and bicubic\n        transform=A.Compose([A.Resize(self.image_size, self.image_size, interpolation=cv2.INTER_AREA)])\n        image= transform(image=image)['image']\n        image = torch.tensor(np.transpose(image, (2, 0, 1)))\n        return self.indexs[idx], image, torch.tensor(np.array([orig_size[0], orig_size[1]]))\n    \n\n############################################### main ##################################################\nimport pickle\ndef main_worker(rank, args, queue):\n    \n    torch.backends.cudnn_benchmark = True\n    \n    # set device\n    device = torch.device(f\"cuda:{rank}\")\n    \n    # meta info\n    volume_shape = args.volume_shape\n    volume_path = args.volume_path\n        \n    # build model\n    model = Ensemble(args.backbone, args.in_channels, args.num_classes, args.ckpt_path, device)\n    \n    # inference \n    with torch.no_grad():\n        for size in args.image_size:\n            for axis in args.axis:\n                test_dataset = InferenceDataset(volume_path, volume_shape, rank, args.num_processes, args.in_channels, image_size=size, axis=axis)\n                test_loader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=4, pin_memory=True)\n                max_len = test_dataset.volume_shape[test_dataset.axis2dim[axis]]\n                pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc=f'Inference {args.group} {axis}', ncols=150)\n                for step, (idx, images, shapes) in pbar:\n                    #print(\"loop: \", images.shape, idx, shapes)\n                    shape = shapes[0].numpy()\n                    idx = idx.numpy()\n                    images = images.to(device, non_blocking=True)\n                    bsz = images.size(0)\n                    batch_pred_mask = torch.zeros(bsz, args.num_classes, shape[0], shape[1]).to(device)\n                    for aug, flip in zip([torch.flip]*len(args.flip)+[partial(torch.rot90, dims=[2, 3])]*len(args.rot), args.flip+args.rot):\n                        with torch.cuda.amp.autocast(enabled=True):\n                            tmp = aug(images, flip)\n                            #print(\"aug: \", tmp.shape)\n                            preds = model(tmp)\n                            #print(\"preds: \", preds.shape)\n                            flip = -flip if not isinstance(flip, list) else flip\n                            preds = F.interpolate(aug(preds, flip).float(), (int(shape[0]), int(shape[1])), mode='bicubic')\n                            #print(\"flip: \", preds.shape)\n                        batch_pred_mask += preds\n                    \n                    batch_pred_mask /= len(args.axis) * (len(args.flip)+len(args.rot)) * len(args.image_size)\n                    if args.overlap:\n                        batch_pred_mask /= args.num_classes\n                    masks = batch_pred_mask.to(torch.float16).cpu().numpy()\n                    queue.put((axis, idx, masks, max_len))\n                    pbar.set_postfix(shape=images.shape)\n                        \n                        \ndef write_worker(args, queue, write_lock):\n    while True:\n        axis, idx, masks, max_len = queue.get()\n        if idx is None:\n            break\n        with write_lock:\n            pred_masks = np.memmap(args.mask_path, shape=args.volume_shape, dtype=np.float16, mode=\"r+\")\n            if args.overlap:\n                for i in range(args.num_classes):\n                    mask = masks[:, i, ...]\n                    offset = i - args.num_classes // 2\n                    idxs = np.clip(idx+offset, 0, max_len-1)\n                    if axis == \"z\":\n                        pred_masks[idxs, :, :] += mask\n                    elif axis == \"y\":\n                        pred_masks[:, idxs, :] += mask.transpose(1, 0, 2)\n                    else:\n                        pred_masks[:, :, idxs] += mask.transpose(1, 2, 0)\n            else:\n                mask = masks[:, args.num_classes//2, ...]\n                idxs = np.clip(idx, 0, max_len-1)\n                if axis == \"z\":\n                    pred_masks[idxs, :, :] += mask\n                elif axis == \"y\":\n                    pred_masks[:, idxs, :] += mask.transpose(1, 0, 2)\n                else:\n                    pred_masks[:, :, idxs] += mask.transpose(1, 2, 0)\n            pred_masks.flush()\n            del pred_masks, masks, axis, idx, max_len\n            \ndef get_blood_vessel(candidate, block_threshold=100):\n    depth, height, width = candidate.shape\n    checked = np.zeros((depth, height, width), dtype=np.uint8)\n    deltas = tuple(filter(lambda x: x != (0, 0, 0),\n                          map(lambda x: (x[0] - 1, x[1] - 1, x[2] - 1),\n                              zip(*np.where(np.ones((3, 3, 3)))))))\n\n    result = np.zeros((depth, height, width), dtype=np.uint8)\n\n    for start_z, start_y, start_x in zip(*np.where(candidate)):\n        if checked[start_z, start_y, start_x]:\n            continue\n\n        chunk = np.zeros((depth, height, width), dtype=np.uint8)\n\n        stack = deque()\n        stack.append((start_z, start_y, start_x))\n\n        chunk[start_z, start_y, start_x] = checked[start_z, start_y, start_x] = True\n\n        n = 1\n        while stack:\n            z, y, x = stack.pop()\n\n            for delta_x, delta_y, delta_z in deltas:\n                next_z = z + delta_z\n                next_y = y + delta_y\n                next_x = x + delta_x\n\n                if not (0 <= next_z < depth and 0 <= next_y < height and 0 <= next_x < width):\n                    continue\n\n                if not candidate[next_z, next_y, next_x]:\n                    continue\n\n                if chunk[next_z, next_y, next_x]:\n                    continue\n\n                chunk[next_z, next_y, next_x] = checked[next_z, next_y, next_x] = True\n                stack.append((next_z, next_y, next_x))\n\n                n += 1\n\n        if n >= block_threshold:\n            result |= chunk\n\n    return result\n    \nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    \n    parser.add_argument(\"--seed\", type=int, default=42)\n    parser.add_argument(\"--group\", type=str, default=\"kidney_5\")\n    parser.add_argument(\"--backbone\", type=str, default=\"convnext_tiny\")\n    parser.add_argument(\"--in_channels\", type=int, default=3)\n    parser.add_argument(\"--num_classes\", type=int, default=3)\n    parser.add_argument(\"--ckpt_path\", type=str, default=\"\")\n    parser.add_argument(\"--batch_size\", type=int, default=3)\n    parser.add_argument(\"--image_size\", type=int, default=2560)\n    parser.add_argument(\"--axis\", type=str, default=\"z|y|x\")\n    parser.add_argument(\"--flip\", type=int, default=3)\n    parser.add_argument(\"--rot\", type=int, default=3)\n    parser.add_argument(\"--overlap\", action=\"store_true\", default=False)\n    parser.add_argument(\"--threshold\", type=float, default=0.5)\n    \n    args = parser.parse_args()\n    args.image_size = [args.image_size]\n    args.axis = args.axis.split(\"|\")\n    args.flip = [[], [1], [2], [3], [2,3]][:args.flip]\n    args.rot = [1, 2, 3][:args.rot]\n    args.ckpt_path = args.ckpt_path.split(\"|\")\n    args.num_processes = torch.cuda.device_count()\n    \n    ls_images = sorted(glob(os.path.join(\"/kaggle/input/blood-vessel-segmentation\", \"train\", args.group, \"images\", \"*.tif\")))\n    h, w = cv2.imread(ls_images[-1], cv2.IMREAD_UNCHANGED).shape\n    volume_shape = (len(ls_images), h, w)\n    volume_path = f\"/dev/shm/{args.group}.mmap\"\n    mask_path = f\"/dev/shm/{args.group}_mask.mmap\"\n    if not os.path.exists(volume_path):\n        volume = np.memmap(volume_path, shape=volume_shape, dtype=np.uint16, mode=\"w+\")\n        for i, path in enumerate(tqdm(ls_images, total=len(ls_images), desc=f\"Caching {args.group} images\")):\n            image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n            volume[i] = image\n        volume.flush()\n        del volume\n    if not os.path.exists(mask_path):\n        mask = np.memmap(mask_path, shape=volume_shape, dtype=np.float16, mode=\"w+\")\n        mask.fill(0.0)\n        mask.flush()\n        del mask\n    \n    args.volume_shape = volume_shape\n    args.volume_path = volume_path\n    args.mask_path = mask_path\n    \n    # inference\n    queue = mp.Queue()\n    write_lock = mp.Lock()\n    inference_processes = []\n    write_processes = []\n    for rank in range(args.num_processes):\n        p = mp.Process(target=main_worker, args=(rank, args, queue))\n        p.start()\n        inference_processes.append(p)\n    for rank in range(args.num_processes*2):\n        p = mp.Process(target=write_worker, args=(args, queue, write_lock))\n        p.start()\n        write_processes.append(p)\n    for p in inference_processes:\n        p.join()\n    for _ in range(args.num_processes*2):\n        queue.put((None, None, None, None))\n    for p in write_processes:\n        p.join()\n        \n    # write to csv\n    rles, ids = [], []\n    pred_masks = np.memmap(args.mask_path, shape=args.volume_shape, dtype=np.float16, mode=\"r\")\n    binary_masks = (pred_masks > args.threshold).astype(np.uint8)\n    \n\n    \n    dust = 'dfs'\n    \n    if dust =='dust':\n        labeled_masks = cc3d.connected_components(binary_masks, connectivity=26)\n        cleaned_masks = cc3d.dust(labeled_masks, threshold=10, connectivity=26, in_place=False)\n        filtered_masks = (cleaned_masks > 0).astype(np.uint8)\n    elif dust == 'dfs':\n        filtered_masks = get_blood_vessel(binary_masks, block_threshold=10)\n    else:\n        filtered_masks = binary_masks\n\n\n    \n    for i in tqdm(range(len(ls_images)), total=len(ls_images)):\n        pred_mask = filtered_masks[i, :, :]\n        pred_mask = (pred_mask > args.threshold).astype(np.uint8)\n        rle = rle_encode(pred_mask)\n        path = ls_images[i].split(os.path.sep)\n        dataset = path[-3]\n        slice_id, _ = os.path.splitext(path[-1])\n        rles.append(rle)\n        ids.append(f\"{dataset}_{slice_id}\")\n        \n    df = pd.DataFrame.from_dict({\n        \"id\": ids,\n        \"rle\": rles\n    })\n    df.to_csv(f\"{args.group}.csv\", index=False)\n    del pred_masks\n    del binary_masks\n    \n    if dust == 'dust':\n        del labeled_masks\n        del filtered_masks\n    elif dust== 'dfs':\n        del filtered_masks\n        \n    # clean up memmap files\n    os.remove(args.volume_path)\n    os.remove(args.mask_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T11:05:44.578181Z","iopub.execute_input":"2024-11-16T11:05:44.578931Z","iopub.status.idle":"2024-11-16T11:05:44.595759Z","shell.execute_reply.started":"2024-11-16T11:05:44.578889Z","shell.execute_reply":"2024-11-16T11:05:44.594817Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Writing inference.py\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom glob import glob\n\ndebug = False\n\nif len(glob(\"/kaggle/input/blood-vessel-segmentation/test/kidney_5/images/*.tif\")) == 3 and not debug:\n    ids = [f\"kidney_5_{i:04d}\" for i in range(3)] + [f\"kidney_6_{i:04d}\" for i in range(3)]\n    rles = [\"1 0\"] * 6\n    submission = pd.DataFrame.from_dict({\n        \"id\": ids,\n        \"rle\": rles\n    })\nelse:\n    !bash inference.sh\n    kidney_5 = pd.read_csv(\"kidney_5.csv\")\n    kidney_6 = pd.read_csv(\"kidney_6.csv\")\n    submission = pd.concat([kidney_5, kidney_6]).reset_index(drop=True)\n    \nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T11:07:40.293920Z","iopub.execute_input":"2024-11-16T11:07:40.294300Z","iopub.status.idle":"2024-11-16T16:05:50.811118Z","shell.execute_reply.started":"2024-11-16T11:07:40.294272Z","shell.execute_reply":"2024-11-16T16:05:50.808238Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c107WarningC1ENS_7variantIJNS0_11UserWarningENS0_18DeprecationWarningEEEERKNS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nCaching kidney_3_sparse images: 100%|███████| 1035/1035 [01:33<00:00, 11.07it/s]\n/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\nInference kidney_3_sparse z: 100%|██████████████████████████████████████████| 259/259 [2:35:09<00:00, 35.94s/it, shape=torch.Size([1, 3, 3072, 3072])]\nInference kidney_3_sparse y:  65%|█████████████████████████▉              | 277/427 [2:20:22<1:16:11, 30.48s/it, shape=torch.Size([2, 3, 3072, 3072])]^C\nProcess ForkProcess-1:4:\nProcess ForkProcess-1:3:\nProcess ForkProcess-1:2:\nProcess Process-6:\nProcess ForkProcess-1:1:\nProcess Process-4:\nProcess Process-5:\nProcess Process-3:\nTraceback (most recent call last):\n  File \"/kaggle/working/inference.py\", line 347, in <module>\nInference kidney_3_sparse y:  65%|█████████████████████████▉              | 277/427 [2:20:49<1:16:15, 30.50s/it, shape=torch.Size([2, 3, 3072, 3072])]\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/inference.py\", line 210, in write_worker\n    axis, idx, masks, max_len = queue.get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nTraceback (most recent call last):\n    p.join()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n    call_item = call_queue.get(block=True)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 149, in join\n    res = self._popen.wait(timeout)\n  File \"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py\", line 43, in wait\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n  File \"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py\", line 27, in poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n    call_item = call_queue.get(block=True)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n    res = self._recv_bytes()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n    buf = self._recv(4)\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n    call_item = call_queue.get(block=True)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n    call_item = call_queue.get(block=True)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/inference.py\", line 210, in write_worker\n    axis, idx, masks, max_len = queue.get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/inference.py\", line 210, in write_worker\n    axis, idx, masks, max_len = queue.get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/kaggle/working/inference.py\", line 210, in write_worker\n    axis, idx, masks, max_len = queue.get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n    res = self._recv_bytes()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n    buf = self._recv(4)\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\nKeyboardInterrupt\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbash inference.sh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     kidney_5 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkidney_5.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     kidney_6 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkidney_6.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([kidney_5, kidney_6])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kidney_5.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'kidney_5.csv'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2024-11-16T11:05:44.986499Z","iopub.execute_input":"2024-11-16T11:05:44.986776Z","iopub.status.idle":"2024-11-16T11:05:45.005060Z","shell.execute_reply.started":"2024-11-16T11:05:44.986751Z","shell.execute_reply":"2024-11-16T11:05:45.003898Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"              id  rle\n0  kidney_5_0000  1 0\n1  kidney_5_0001  1 0\n2  kidney_5_0002  1 0\n3  kidney_6_0000  1 0\n4  kidney_6_0001  1 0\n5  kidney_6_0002  1 0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kidney_5_0000</td>\n      <td>1 0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kidney_5_0001</td>\n      <td>1 0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kidney_5_0002</td>\n      <td>1 0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kidney_6_0000</td>\n      <td>1 0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kidney_6_0001</td>\n      <td>1 0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>kidney_6_0002</td>\n      <td>1 0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13}]}